{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexhang/project/Nuclear'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "path = os.getcwd()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kinf_1</th>\n",
       "      <th>kinf_2</th>\n",
       "      <th>kinf_3</th>\n",
       "      <th>kinf_4</th>\n",
       "      <th>kinf_5</th>\n",
       "      <th>kinf_6</th>\n",
       "      <th>kinf_7</th>\n",
       "      <th>kinf_8</th>\n",
       "      <th>kinf_9</th>\n",
       "      <th>kinf_10</th>\n",
       "      <th>...</th>\n",
       "      <th>NODE2DBU_95</th>\n",
       "      <th>NODE2DBU_96</th>\n",
       "      <th>NODE2DBU_97</th>\n",
       "      <th>NODE2DBU_98</th>\n",
       "      <th>NODE2DBU_99</th>\n",
       "      <th>NODE2DBU_100</th>\n",
       "      <th>NODE2DBU_101</th>\n",
       "      <th>NODE2DBU_102</th>\n",
       "      <th>NODE2DBU_103</th>\n",
       "      <th>NODE2DBU_104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.16662</td>\n",
       "      <td>1.07459</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15078</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.16662</td>\n",
       "      <td>1.07459</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15078</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.16662</td>\n",
       "      <td>1.07459</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15078</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.16662</td>\n",
       "      <td>1.07459</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15078</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.16708</td>\n",
       "      <td>1.08099</td>\n",
       "      <td>1.18090</td>\n",
       "      <td>1.16216</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.08632</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26837.0</td>\n",
       "      <td>26864.0</td>\n",
       "      <td>26834.0</td>\n",
       "      <td>26862.0</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>22008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>1.15988</td>\n",
       "      <td>1.07458</td>\n",
       "      <td>1.09861</td>\n",
       "      <td>1.15534</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.07427</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26191.0</td>\n",
       "      <td>26191.0</td>\n",
       "      <td>26200.0</td>\n",
       "      <td>26200.0</td>\n",
       "      <td>36146.0</td>\n",
       "      <td>36146.0</td>\n",
       "      <td>36146.0</td>\n",
       "      <td>36146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>1.09092</td>\n",
       "      <td>1.08161</td>\n",
       "      <td>1.07427</td>\n",
       "      <td>1.07583</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.09178</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43151.0</td>\n",
       "      <td>45258.0</td>\n",
       "      <td>39658.0</td>\n",
       "      <td>43091.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>1.09092</td>\n",
       "      <td>1.08161</td>\n",
       "      <td>1.07427</td>\n",
       "      <td>1.07583</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.09178</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43091.0</td>\n",
       "      <td>39658.0</td>\n",
       "      <td>45258.0</td>\n",
       "      <td>43151.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>1.19730</td>\n",
       "      <td>1.15417</td>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.20422</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.06296</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>25238.0</td>\n",
       "      <td>25238.0</td>\n",
       "      <td>25238.0</td>\n",
       "      <td>25238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>1.06622</td>\n",
       "      <td>1.16655</td>\n",
       "      <td>1.20028</td>\n",
       "      <td>1.19485</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15935</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42090.0</td>\n",
       "      <td>43835.0</td>\n",
       "      <td>39276.0</td>\n",
       "      <td>42082.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>21568.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         kinf_1   kinf_2   kinf_3   kinf_4  kinf_5  kinf_6   kinf_7  kinf_8  \\\n",
       "0       1.21509  1.16662  1.07459  1.21975  1.4279  1.1821  1.15078  1.4279   \n",
       "1       1.21509  1.16662  1.07459  1.21975  1.4279  1.1821  1.15078  1.4279   \n",
       "2       1.21509  1.16662  1.07459  1.21975  1.4279  1.1821  1.15078  1.4279   \n",
       "3       1.21509  1.16662  1.07459  1.21975  1.4279  1.1821  1.15078  1.4279   \n",
       "4       1.16708  1.08099  1.18090  1.16216  1.4279  1.1821  1.08632  1.4279   \n",
       "...         ...      ...      ...      ...     ...     ...      ...     ...   \n",
       "119995  1.15988  1.07458  1.09861  1.15534  1.4279  1.1821  1.07427  1.4279   \n",
       "119996  1.09092  1.08161  1.07427  1.07583  1.4279  1.1821  1.09178  1.4279   \n",
       "119997  1.09092  1.08161  1.07427  1.07583  1.4279  1.1821  1.09178  1.4279   \n",
       "119998  1.19730  1.15417  1.21509  1.20422  1.4279  1.1821  1.06296  1.4279   \n",
       "119999  1.06622  1.16655  1.20028  1.19485  1.4279  1.1821  1.15935  1.4279   \n",
       "\n",
       "        kinf_9  kinf_10  ...  NODE2DBU_95  NODE2DBU_96  NODE2DBU_97  \\\n",
       "0       1.1821   1.1821  ...          0.0          0.0      36445.0   \n",
       "1       1.1821   1.1821  ...          0.0          0.0      36809.0   \n",
       "2       1.1821   1.1821  ...          0.0          0.0      31836.0   \n",
       "3       1.1821   1.1821  ...          0.0          0.0      31803.0   \n",
       "4       1.1821   1.1821  ...          0.0          0.0      26837.0   \n",
       "...        ...      ...  ...          ...          ...          ...   \n",
       "119995  1.1821   1.1821  ...          0.0          0.0      26191.0   \n",
       "119996  1.1821   1.1821  ...          0.0          0.0      43151.0   \n",
       "119997  1.1821   1.1821  ...          0.0          0.0      43091.0   \n",
       "119998  1.1821   1.1821  ...          0.0          0.0      31803.0   \n",
       "119999  1.1821   1.1821  ...          0.0          0.0      42090.0   \n",
       "\n",
       "        NODE2DBU_98  NODE2DBU_99  NODE2DBU_100  NODE2DBU_101  NODE2DBU_102  \\\n",
       "0           31803.0      36809.0       31836.0       20806.0       20806.0   \n",
       "1           36445.0      31836.0       31803.0       20806.0       20806.0   \n",
       "2           36809.0      31803.0       36445.0       20806.0       20806.0   \n",
       "3           31836.0      36445.0       36809.0       20806.0       20806.0   \n",
       "4           26864.0      26834.0       26862.0       22008.0       22008.0   \n",
       "...             ...          ...           ...           ...           ...   \n",
       "119995      26191.0      26200.0       26200.0       36146.0       36146.0   \n",
       "119996      45258.0      39658.0       43091.0       36186.0       36186.0   \n",
       "119997      39658.0      45258.0       43151.0       36186.0       36186.0   \n",
       "119998      31836.0      36445.0       36809.0       25238.0       25238.0   \n",
       "119999      43835.0      39276.0       42082.0       21568.0       21568.0   \n",
       "\n",
       "        NODE2DBU_103  NODE2DBU_104  \n",
       "0            20806.0       20806.0  \n",
       "1            20806.0       20806.0  \n",
       "2            20806.0       20806.0  \n",
       "3            20806.0       20806.0  \n",
       "4            22008.0       22008.0  \n",
       "...              ...           ...  \n",
       "119995       36146.0       36146.0  \n",
       "119996       36186.0       36186.0  \n",
       "119997       36186.0       36186.0  \n",
       "119998       25238.0       25238.0  \n",
       "119999       21568.0       21568.0  \n",
       "\n",
       "[120000 rows x 156 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入处理好的数据\n",
    "file_base_name = 'nuclear_burnup_data_20201215.csv'\n",
    "file_input_name = 'df.csv'\n",
    "\n",
    "pre_data_X = pd.read_csv(os.path.join(path, file_input_name), index_col=0)\n",
    "pre_data_base = pd.read_csv(os.path.join(path, file_base_name))\n",
    "pre_data_X.columns.values.tolist()  \n",
    "pre_data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAssBurnupCal</th>\n",
       "      <th>MaxPinBurnupCal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56624</td>\n",
       "      <td>62467.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56812</td>\n",
       "      <td>61980.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56724</td>\n",
       "      <td>62521.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56537</td>\n",
       "      <td>62195.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57424</td>\n",
       "      <td>64025.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>57359</td>\n",
       "      <td>63599.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>59562</td>\n",
       "      <td>64865.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>59631</td>\n",
       "      <td>63716.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>61714</td>\n",
       "      <td>65601.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>61843</td>\n",
       "      <td>66948.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MaxAssBurnupCal  MaxPinBurnupCal\n",
       "0                 56624          62467.5\n",
       "1                 56812          61980.1\n",
       "2                 56724          62521.4\n",
       "3                 56537          62195.7\n",
       "4                 57424          64025.7\n",
       "...                 ...              ...\n",
       "119995            57359          63599.1\n",
       "119996            59562          64865.4\n",
       "119997            59631          63716.2\n",
       "119998            61714          65601.8\n",
       "119999            61843          66948.3\n",
       "\n",
       "[120000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data_y = pre_data_base.iloc[:,-2:]\n",
    "pre_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kinf_1</th>\n",
       "      <th>kinf_2</th>\n",
       "      <th>kinf_3</th>\n",
       "      <th>kinf_4</th>\n",
       "      <th>kinf_5</th>\n",
       "      <th>kinf_6</th>\n",
       "      <th>kinf_7</th>\n",
       "      <th>kinf_8</th>\n",
       "      <th>kinf_9</th>\n",
       "      <th>kinf_10</th>\n",
       "      <th>...</th>\n",
       "      <th>NODE2DBU_97</th>\n",
       "      <th>NODE2DBU_98</th>\n",
       "      <th>NODE2DBU_99</th>\n",
       "      <th>NODE2DBU_100</th>\n",
       "      <th>NODE2DBU_101</th>\n",
       "      <th>NODE2DBU_102</th>\n",
       "      <th>NODE2DBU_103</th>\n",
       "      <th>NODE2DBU_104</th>\n",
       "      <th>MaxAssBurnupCal</th>\n",
       "      <th>MaxPinBurnupCal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.16662</td>\n",
       "      <td>1.07459</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15078</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>56624</td>\n",
       "      <td>62467.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.16662</td>\n",
       "      <td>1.07459</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15078</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>56812</td>\n",
       "      <td>61980.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.16662</td>\n",
       "      <td>1.07459</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15078</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>56724</td>\n",
       "      <td>62521.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.16662</td>\n",
       "      <td>1.07459</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15078</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>20806.0</td>\n",
       "      <td>56537</td>\n",
       "      <td>62195.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.16708</td>\n",
       "      <td>1.08099</td>\n",
       "      <td>1.18090</td>\n",
       "      <td>1.16216</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.08632</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>26837.0</td>\n",
       "      <td>26864.0</td>\n",
       "      <td>26834.0</td>\n",
       "      <td>26862.0</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>22008.0</td>\n",
       "      <td>57424</td>\n",
       "      <td>64025.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>1.15988</td>\n",
       "      <td>1.07458</td>\n",
       "      <td>1.09861</td>\n",
       "      <td>1.15534</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.07427</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>26191.0</td>\n",
       "      <td>26191.0</td>\n",
       "      <td>26200.0</td>\n",
       "      <td>26200.0</td>\n",
       "      <td>36146.0</td>\n",
       "      <td>36146.0</td>\n",
       "      <td>36146.0</td>\n",
       "      <td>36146.0</td>\n",
       "      <td>57359</td>\n",
       "      <td>63599.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>1.09092</td>\n",
       "      <td>1.08161</td>\n",
       "      <td>1.07427</td>\n",
       "      <td>1.07583</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.09178</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>43151.0</td>\n",
       "      <td>45258.0</td>\n",
       "      <td>39658.0</td>\n",
       "      <td>43091.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>59562</td>\n",
       "      <td>64865.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>1.09092</td>\n",
       "      <td>1.08161</td>\n",
       "      <td>1.07427</td>\n",
       "      <td>1.07583</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.09178</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>43091.0</td>\n",
       "      <td>39658.0</td>\n",
       "      <td>45258.0</td>\n",
       "      <td>43151.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>36186.0</td>\n",
       "      <td>59631</td>\n",
       "      <td>63716.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>1.19730</td>\n",
       "      <td>1.15417</td>\n",
       "      <td>1.21509</td>\n",
       "      <td>1.20422</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.06296</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>31803.0</td>\n",
       "      <td>31836.0</td>\n",
       "      <td>36445.0</td>\n",
       "      <td>36809.0</td>\n",
       "      <td>25238.0</td>\n",
       "      <td>25238.0</td>\n",
       "      <td>25238.0</td>\n",
       "      <td>25238.0</td>\n",
       "      <td>61714</td>\n",
       "      <td>65601.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>1.06622</td>\n",
       "      <td>1.16655</td>\n",
       "      <td>1.20028</td>\n",
       "      <td>1.19485</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.15935</td>\n",
       "      <td>1.4279</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>1.1821</td>\n",
       "      <td>...</td>\n",
       "      <td>42090.0</td>\n",
       "      <td>43835.0</td>\n",
       "      <td>39276.0</td>\n",
       "      <td>42082.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>61843</td>\n",
       "      <td>66948.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         kinf_1   kinf_2   kinf_3   kinf_4  kinf_5  kinf_6   kinf_7  kinf_8  \\\n",
       "0       1.21509  1.16662  1.07459  1.21975  1.4279  1.1821  1.15078  1.4279   \n",
       "1       1.21509  1.16662  1.07459  1.21975  1.4279  1.1821  1.15078  1.4279   \n",
       "2       1.21509  1.16662  1.07459  1.21975  1.4279  1.1821  1.15078  1.4279   \n",
       "3       1.21509  1.16662  1.07459  1.21975  1.4279  1.1821  1.15078  1.4279   \n",
       "4       1.16708  1.08099  1.18090  1.16216  1.4279  1.1821  1.08632  1.4279   \n",
       "...         ...      ...      ...      ...     ...     ...      ...     ...   \n",
       "119995  1.15988  1.07458  1.09861  1.15534  1.4279  1.1821  1.07427  1.4279   \n",
       "119996  1.09092  1.08161  1.07427  1.07583  1.4279  1.1821  1.09178  1.4279   \n",
       "119997  1.09092  1.08161  1.07427  1.07583  1.4279  1.1821  1.09178  1.4279   \n",
       "119998  1.19730  1.15417  1.21509  1.20422  1.4279  1.1821  1.06296  1.4279   \n",
       "119999  1.06622  1.16655  1.20028  1.19485  1.4279  1.1821  1.15935  1.4279   \n",
       "\n",
       "        kinf_9  kinf_10  ...  NODE2DBU_97  NODE2DBU_98  NODE2DBU_99  \\\n",
       "0       1.1821   1.1821  ...      36445.0      31803.0      36809.0   \n",
       "1       1.1821   1.1821  ...      36809.0      36445.0      31836.0   \n",
       "2       1.1821   1.1821  ...      31836.0      36809.0      31803.0   \n",
       "3       1.1821   1.1821  ...      31803.0      31836.0      36445.0   \n",
       "4       1.1821   1.1821  ...      26837.0      26864.0      26834.0   \n",
       "...        ...      ...  ...          ...          ...          ...   \n",
       "119995  1.1821   1.1821  ...      26191.0      26191.0      26200.0   \n",
       "119996  1.1821   1.1821  ...      43151.0      45258.0      39658.0   \n",
       "119997  1.1821   1.1821  ...      43091.0      39658.0      45258.0   \n",
       "119998  1.1821   1.1821  ...      31803.0      31836.0      36445.0   \n",
       "119999  1.1821   1.1821  ...      42090.0      43835.0      39276.0   \n",
       "\n",
       "        NODE2DBU_100  NODE2DBU_101  NODE2DBU_102  NODE2DBU_103  NODE2DBU_104  \\\n",
       "0            31836.0       20806.0       20806.0       20806.0       20806.0   \n",
       "1            31803.0       20806.0       20806.0       20806.0       20806.0   \n",
       "2            36445.0       20806.0       20806.0       20806.0       20806.0   \n",
       "3            36809.0       20806.0       20806.0       20806.0       20806.0   \n",
       "4            26862.0       22008.0       22008.0       22008.0       22008.0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "119995       26200.0       36146.0       36146.0       36146.0       36146.0   \n",
       "119996       43091.0       36186.0       36186.0       36186.0       36186.0   \n",
       "119997       43151.0       36186.0       36186.0       36186.0       36186.0   \n",
       "119998       36809.0       25238.0       25238.0       25238.0       25238.0   \n",
       "119999       42082.0       21568.0       21568.0       21568.0       21568.0   \n",
       "\n",
       "        MaxAssBurnupCal  MaxPinBurnupCal  \n",
       "0                 56624          62467.5  \n",
       "1                 56812          61980.1  \n",
       "2                 56724          62521.4  \n",
       "3                 56537          62195.7  \n",
       "4                 57424          64025.7  \n",
       "...                 ...              ...  \n",
       "119995            57359          63599.1  \n",
       "119996            59562          64865.4  \n",
       "119997            59631          63716.2  \n",
       "119998            61714          65601.8  \n",
       "119999            61843          66948.3  \n",
       "\n",
       "[120000 rows x 158 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_data = pd.concat([pre_data_X, pre_data_y], axis=1)\n",
    "pre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 156)\n",
      "(120000, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pre_data_array = pre_data.values\n",
    "mm = MinMaxScaler(feature_range=(0,1))\n",
    "pre_data_Normalized = mm.fit_transform(pre_data_array)\n",
    "pre_data_Normalized = pre_data_Normalized[:,:-2]  # 删除y目标被均一化的列\n",
    "# pre_data_y = pre_data_Normalized[:,-2:]\n",
    "print(pre_data_Normalized.shape)\n",
    "print(pre_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15)\n",
      "(30, 30)\n"
     ]
    }
   ],
   "source": [
    "map1 = \\\n",
    "[\n",
    "    [0,0,0,0,0,0,1,2,1,0,0,0,0,0,0],\n",
    "    [0,0,0,0,3,4,5,6,5,4,3,0,0,0,0],\n",
    "    [0,0,0,7,8,9,10,11,10,9,8,7,0,0,0],\n",
    "    [0,0,7,12,13,14,15,16,15,14,13,12,7,0,0],\n",
    "    [0,3,8,13,17,18,19,20,19,18,17,13,8,3,0],\n",
    "    [0,4,9,14,18,21,22,23,22,21,18,14,9,4,0],\n",
    "    [1,5,10,15,19,22,24,25,24,22,19,15,10,5,1],\n",
    "    [2,6,11,16,20,23,25,26,25,23,20,16,11,6,2],\n",
    "    [1,5,10,15,19,22,24,25,24,22,19,15,10,5,1],\n",
    "    [0,4,9,14,18,21,22,23,22,21,18,14,9,4,0],\n",
    "    [0,3,8,13,17,18,19,20,19,18,17,13,8,3,0],\n",
    "    [0,0,7,12,13,14,15,16,15,14,13,12,7,0,0],\n",
    "    [0,0,0,7,8,9,10,11,10,9,8,7,0,0,0],\n",
    "    [0,0,0,0,3,4,5,6,5,4,3,0,0,0,0],\n",
    "    [0,0,0,0,0,0,1,2,1,0,0,0,0,0,0]\n",
    "    \n",
    "]\n",
    "m = np.array(map1)\n",
    "print(m.shape)\n",
    "map2 = \\\n",
    "[\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,\"1/0\",'1/1','2/0','2/1','1/1','1/0',0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,\"1/2\",'1/3','2/2','2/3','1/3','1/2',0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,\"3/0\",'3/1','4/0','4/1','5/0','5/1','6/0','6/1',\"3/1\",'3/0','4/1','4/0','5/1','5/0',0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,\"3/2\",'3/3','4/2','4/3','5/2','5/3','6/2','6/3',\"3/3\",'3/2','4/3','4/2','5/3','5/2',0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,'7/0','7/1',\"8/0\",'8/1','9/0','9/1','10/0','10/1','11/0','11/1',\"10/1\",'10/0','9/1','9/0','8/1','8/0','7/1','7/0',0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,'7/2','7/3',\"8/2\",'8/3','9/2','9/3','10/2','10/3','11/2','11/3',\"10/3\",'10/2','9/3','9/2','8/3','8/2','7/3','7/2',0,0,0,0,0,0],\n",
    "    [0,0,0,0,'7/0','7/2','12/0','12/1',\"13/0\",'13/1','14/0','14/1','15/0','15/1','16/0','16/1',\"15/1\",'15/0','14/1','14/0','13/1','13/0','12/1','12/0','7/2','7/0',0,0,0,0],\n",
    "    [0,0,0,0,'7/1','7/3','12/2','12/3',\"13/2\",'13/3','14/2','14/3','15/2','15/3','16/2','16/3',\"15/3\",'15/2','14/3','14/2','13/3','13/2','12/3','12/2','7/3','7/1',0,0,0,0],\n",
    "    [0,0,\"3/0\",\"3/2\",'8/0','8/2','13/0','13/2',\"17/0\",'17/1','18/0','18/1','19/0','19/1','20/0','20/1',\"19/1\",'19/0','18/1','18/0','17/1','17/0','13/2','13/0','8/2','8/0','3/2','3/0',0,0],\n",
    "    [0,0,\"3/1\",\"3/3\",'8/1','8/3','13/1','13/3',\"17/2\",'17/3','18/2','18/3','19/2','19/3','20/2','20/3',\"19/3\",'19/2','18/3','18/2','17/3','17/2','13/3','13/1','8/3','8/1','3/3','3/1',0,0],\n",
    "    [0,0,\"4/0\",\"4/2\",'9/0','9/2','14/0','14/2',\"18/0\",'18/2','21/0','21/1','22/0','22/1','23/0','23/1',\"22/1\",'22/0','21/1','21/0','18/2','18/0','14/2','14/0','9/2','9/0','4/2','4/0',0,0],\n",
    "    [0,0,\"4/1\",\"4/3\",'9/1','9/3','14/1','14/3',\"18/1\",'18/3','21/2','21/3','22/2','22/3','23/2','23/3',\"22/3\",'22/2','21/3','21/2','18/3','18/1','14/3','14/1','9/3','9/1','4/3','4/1',0,0],\n",
    "    ['1/0','1/2',\"5/0\",\"5/2\",'10/0','10/2','15/0','15/2',\"19/0\",'19/2','22/0','22/2','24/0','24/1','25/0','25/1',\"24/1\",'24/0','22/2','22/0','19/2','19/0','15/2','15/0','10/2','10/0','5/2','5/0','1/2','1/0'],\n",
    "    ['1/1','1/3',\"5/1\",\"5/3\",'10/1','10/3','15/1','15/3',\"19/1\",'19/3','22/1','22/3','24/2','24/3','25/2','25/3',\"24/3\",'24/2','22/3','22/1','19/3','19/1','15/3','15/1','10/3','10/1','5/3','5/1','1/3','1/1'],\n",
    "    ['2/0','2/2',\"6/0\",\"6/2\",'11/0','11/2','16/0','16/2',\"20/0\",'20/2','23/0','23/2','25/0','25/2','26/0','26/1',\"25/2\",'25/0','23/2','23/0','20/2','20/0','16/2','16/0','11/2','11/0','6/2','6/0','2/2','2/0'],\n",
    "    ['2/1','2/3',\"6/1\",\"6/3\",'11/1','11/3','16/1','16/3',\"20/1\",'20/3','23/1','23/3','25/1','25/3','26/2','26/3',\"25/3\",'25/1','23/3','23/1','20/3','20/1','16/3','16/1','11/3','11/1','6/3','6/1','2/3','2/1'],\n",
    "    ['1/1','1/3',\"5/1\",\"5/3\",'10/1','10/3','15/1','15/3',\"19/1\",'19/3','22/1','22/3','24/2','24/3','25/2','25/3',\"24/3\",'24/2','22/3','22/1','19/3','19/1','15/3','15/1','10/3','10/1','5/3','5/1','1/3','1/1'],\n",
    "    ['1/0','1/2',\"5/0\",\"5/2\",'10/0','10/2','15/0','15/2',\"19/0\",'19/2','22/0','22/2','24/0','24/1','25/0','25/1',\"24/1\",'24/0','22/2','22/0','19/2','19/0','15/2','15/0','10/2','10/0','5/2','5/0','1/2','1/0'],\n",
    "    [0,0,\"4/1\",\"4/3\",'9/1','9/3','14/1','14/3',\"18/1\",'18/3','21/2','21/3','22/2','22/3','23/2','23/3',\"22/3\",'22/2','21/3','21/2','18/3','18/1','14/3','14/1','9/3','9/1','4/3','4/1',0,0],\n",
    "    [0,0,\"4/0\",\"4/2\",'9/0','9/2','14/0','14/2',\"18/0\",'18/2','21/0','21/1','22/0','22/1','23/0','23/1',\"22/1\",'22/0','21/1','21/0','18/2','18/0','14/2','14/0','9/2','9/0','4/2','4/0',0,0],\n",
    "    [0,0,\"3/1\",\"3/3\",'8/1','8/3','13/1','13/3',\"17/2\",'17/3','18/2','18/3','19/2','19/3','20/2','20/3',\"19/3\",'19/2','18/3','18/2','17/3','17/2','13/3','13/1','8/3','8/1','3/3','3/1',0,0],\n",
    "    [0,0,\"3/0\",\"3/2\",'8/0','8/2','13/0','13/2',\"17/0\",'17/1','18/0','18/1','19/0','19/1','20/0','20/1',\"19/1\",'19/0','18/1','18/0','17/1','17/0','13/2','13/0','8/2','8/0','3/2','3/0',0,0],\n",
    "    [0,0,0,0,'7/1','7/3','12/2','12/3',\"13/2\",'13/3','14/2','14/3','15/2','15/3','16/2','16/3',\"15/3\",'15/2','14/3','14/2','13/3','13/2','12/3','12/2','7/3','7/1',0,0,0,0],\n",
    "    [0,0,0,0,'7/0','7/2','12/0','12/1',\"13/0\",'13/1','14/0','14/1','15/0','15/1','16/0','16/1',\"15/1\",'15/0','14/1','14/0','13/1','13/0','12/1','12/0','7/2','7/0',0,0,0,0],\n",
    "    [0,0,0,0,0,0,'7/2','7/3',\"8/2\",'8/3','9/2','9/3','10/2','10/3','11/2','11/3',\"10/3\",'10/2','9/3','9/2','8/3','8/2','7/3','7/2',0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,'7/0','7/1',\"8/0\",'8/1','9/0','9/1','10/0','10/1','11/0','11/1',\"10/1\",'10/0','9/1','9/0','8/1','8/0','7/1','7/0',0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,\"3/2\",'3/3','4/2','4/3','5/2','5/3','6/2','6/3',\"3/3\",'3/2','4/3','4/2','5/3','5/2',0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,\"3/0\",'3/1','4/0','4/1','5/0','5/1','6/0','6/1',\"3/1\",'3/0','4/1','4/0','5/1','5/0',0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,\"1/2\",'1/3','2/2','2/3','1/3','1/2',0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,0,0,0,0,0,\"1/0\",'1/1','2/0','2/1','1/1','1/0',0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "      \n",
    "]\n",
    "m = np.array(map2)\n",
    "print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(a,alist):\n",
    "    res = []\n",
    "    for i in range(len(alist)):\n",
    "        for j in range(len(alist[i])):\n",
    "            if alist[i][j] == a:\n",
    "                res.append((i,j))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#排布input\n",
    "# def search(a,alist):\n",
    "#     res = []\n",
    "#     for i in range(len(alist)):\n",
    "#         for j in range(len(alist[i])):\n",
    "#             if alist[i][j] == a:\n",
    "#                 res.append((i,j))\n",
    "#     return res\n",
    "# new = []\n",
    "# for i,item in enumerate(pre_data_Normalized):\n",
    "#     print(\"正在处理第 \"+str(i)+' 个图像..')\n",
    "#     layer1 = [[0 for _ in range(15)] for _ in range(15)]\n",
    "#     layer2 = [[0 for _ in range(15)] for _ in range(15)]\n",
    "#     layer3 = [[0 for _ in range(30)] for _ in range(30)]\n",
    "# #     print(item)\n",
    "#     for j in range(item.size): #len = 156\n",
    "#         if j < 26:\n",
    "#             res = search(j+1,map1)\n",
    "#             for u in res:\n",
    "#                 h,w = u[0],u[1]\n",
    "#                 layer1[h][w] = item[j]\n",
    "#         elif j < 52:\n",
    "#             j_ = j-26\n",
    "#             res = search(j_+1,map1)\n",
    "#             for u in res:\n",
    "#                 h,w = u[0],u[1]\n",
    "#                 layer2[h][w] = item[j]\n",
    "            \n",
    "#         else:\n",
    "#             j_ = j-52\n",
    "#             number = str(j_ // 4 + 1)\n",
    "#             corner = str(j_ % 4)\n",
    "#             number_corner = number + '/' + corner\n",
    "#             res = search(number_corner,map2)\n",
    "#             for u in res:\n",
    "#                 h,w = u[0],u[1]\n",
    "#                 layer3[h][w] = item[j]\n",
    "#     layer1_array = np.array(layer1)\n",
    "#     layer2_array = np.array(layer2)\n",
    "#     layer3_array = np.array(layer3)\n",
    "    \n",
    "#     #从1*1扩展成2*2\n",
    "#     layer1_array = np.repeat(layer1_array,2,axis = 1) \n",
    "#     layer1_array = np.repeat(layer1_array,2,axis = 0)\n",
    "#     layer2_array = np.repeat(layer2_array,2,axis = 1)\n",
    "#     layer2_array = np.repeat(layer2_array,2,axis = 0)\n",
    "    \n",
    "#     #channel 拼接\n",
    "#     tmp = np.stack((layer1_array,layer2_array,layer3_array),axis = 2)\n",
    "#     new.append(tmp)\n",
    "\n",
    "# pre_data_x = np.array(new)\n",
    "# print(pre_data_x.shape)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"pre_data_x_tmp.npy\",pre_data_x) \n",
    "pre_data_x = np.load(\"pre_data_x_tmp.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pre_data_x.shape)\n",
    "# print(pre_data_y)\n",
    "pre_data_y = np.array(pre_data_y)\n",
    "# print(pre_data_y)\n",
    "# pre_data_y = pre_data_y[0:100,:]\n",
    "# print(pre_data_y)\n",
    "# data = (pre_data_x,pre_data_y)\n",
    "# pre_data_y.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 19 09:20:24 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 2070    On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 29%   33C    P8     3W / 175W |    318MiB /  7979MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0       918      G   /usr/lib/xorg/Xorg                           176MiB |\r\n",
      "|    0      1950      G   /usr/bin/gnome-shell                         126MiB |\r\n",
      "|    0     18318      G   /usr/local/sunlogin/bin/sunloginclient         7MiB |\r\n",
      "|    0     23353      G   /usr/lib/firefox/firefox                       2MiB |\r\n",
      "|    0     32188      G   /usr/lib/firefox/firefox                       2MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    " \n",
    "if gpus:\n",
    "    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n",
    "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
    "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
    "    tf.config.set_visible_devices([gpu0],\"GPU\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras.applications.resnet18 import ResNet18\n",
    "# from keras.applications.resnet18 import preprocess_input as preprocess_input_resnet\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# import tensorflow.keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "def deeper_conv2D(h,w):\n",
    "    new_model = tf.keras.Sequential()\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(2,2), strides=1, padding=\"same\",input_shape=(h, w, 3)))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=2, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    \n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, strides=1, padding=\"same\",input_shape=(h, w, 3)))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=4, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=8, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    \n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2,strides=1, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    \n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=4,strides=1, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=4, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=8, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    \n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    \n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=4, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=4, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=8, padding=\"same\"))\n",
    "    new_model.add(tf.keras.layers.BatchNormalization())\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "#     new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2,padding=\"same\"))\n",
    "#     new_model.add(tf.keras.layers.BatchNormalization())\n",
    "#     new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "#     new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=4, padding=\"same\"))\n",
    "#     new_model.add(tf.keras.layers.BatchNormalization())\n",
    "#     new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "#     new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=8, padding=\"same\"))\n",
    "#     new_model.add(tf.keras.layers.BatchNormalization())\n",
    "#     new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "    \n",
    "#     new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=8, padding=\"same\", activation=\"relu\"))\n",
    "    # Flatten will take our convolution filters and lay them out end to end so our dense layer can predict based on the outcomes of each\n",
    "    new_model.add(tf.keras.layers.Flatten())\n",
    "#     new_model.add(tf.keras.layers.Dense(1000,kernel_regularizer=regularizers.l2(0.01),\\\n",
    "#                 activity_regularizer=regularizers.l1(0.01)))\n",
    "    new_model.add(tf.keras.layers.Dense(1000))\n",
    "    new_model.add(tf.keras.layers.LeakyReLU(alpha=0.05))\n",
    "#     new_model.add(tf.keras.layers.Dropout(0.02))\n",
    "    new_model.add(tf.keras.layers.Dense(100))\n",
    "#     new_model.add(tf.keras.layers.Dense(100,kernel_regularizer=regularizers.l2(0.01),\\\n",
    "#                 activity_regularizer=regularizers.l1(0.01)))\n",
    "#     new_model.add(tf.keras.layers.Dropout(0.02))\n",
    "    new_model.add(tf.keras.layers.Dense(1))\n",
    "    new_model.compile(optimizer=\"adam\", loss=\"mean_absolute_error\")    \n",
    "    return new_model\n",
    "\n",
    "m = deeper_conv2D(pre_data_x.shape[1],pre_data_x.shape[2])\n",
    "m2 = deeper_conv2D(pre_data_x.shape[1],pre_data_x.shape[2])\n",
    "m.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "seed = 2020\n",
    "X_pre_train, X_test, y_pre_train, y_test = train_test_split(pre_data_x, pre_data_y, \n",
    "                                                           random_state=seed, train_size=0.9, \n",
    "                                                           test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "learning_rate = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1, \n",
    "    patience=10, \n",
    "    verbose=0, \n",
    "    mode='auto', \n",
    "    min_delta=0.0001, \n",
    "    cooldown=0, \n",
    "    min_lr=0\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20, \n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义绘制history的函数\n",
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-18\n",
      "fold 1\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 79.4245 - val_loss: 251.4342 - lr: 1.0000e-04\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 76.1214 - val_loss: 55.3273 - lr: 1.0000e-04\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 75.1895 - val_loss: 55.6276 - lr: 1.0000e-04\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 76.5182 - val_loss: 103.3104 - lr: 1.0000e-04\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 75.5190 - val_loss: 103.2932 - lr: 1.0000e-04\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 75.9892 - val_loss: 70.9301 - lr: 1.0000e-04\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 74.7989 - val_loss: 53.9176 - lr: 1.0000e-04\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 75.2224 - val_loss: 131.0541 - lr: 1.0000e-04\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 74.9248 - val_loss: 53.9134 - lr: 1.0000e-04\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 75.4097 - val_loss: 113.8814 - lr: 1.0000e-04\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 75.8172 - val_loss: 145.6373 - lr: 1.0000e-04\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 72.3947 - val_loss: 52.7557 - lr: 1.0000e-04\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 74.5044 - val_loss: 99.6710 - lr: 1.0000e-04\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 73.6051 - val_loss: 71.5150 - lr: 1.0000e-04\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 69.1584 - val_loss: 90.4585 - lr: 1.0000e-04\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 71.1038 - val_loss: 86.7717 - lr: 1.0000e-04\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 72.0796 - val_loss: 54.3256 - lr: 1.0000e-04\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 72.4969 - val_loss: 170.9408 - lr: 1.0000e-04\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 68.4011 - val_loss: 80.0088 - lr: 1.0000e-04\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 69.1448 - val_loss: 51.9607 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 70.1931 - val_loss: 213.7095 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 71.7936 - val_loss: 64.7064 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 67.7842 - val_loss: 246.7431 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 70.5770 - val_loss: 106.3656 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 68.7862 - val_loss: 195.8867 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 70.2721 - val_loss: 224.5100 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 68.4170 - val_loss: 56.9584 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 69.7123 - val_loss: 57.9234 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 66.9625 - val_loss: 64.7480 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 67.6780 - val_loss: 60.9249 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 51.4780 - val_loss: 50.8496 - lr: 1.0000e-05\n",
      "Epoch 32/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 51.0734 - val_loss: 62.6734 - lr: 1.0000e-05\n",
      "Epoch 33/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.5938 - val_loss: 47.7987 - lr: 1.0000e-05\n",
      "Epoch 34/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.5558 - val_loss: 49.7442 - lr: 1.0000e-05\n",
      "Epoch 35/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.6381 - val_loss: 69.1261 - lr: 1.0000e-05\n",
      "Epoch 36/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.9649 - val_loss: 49.2389 - lr: 1.0000e-05\n",
      "Epoch 37/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.0718 - val_loss: 49.7412 - lr: 1.0000e-05\n",
      "Epoch 38/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.0609 - val_loss: 48.5464 - lr: 1.0000e-05\n",
      "Epoch 39/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.7407 - val_loss: 81.6594 - lr: 1.0000e-05\n",
      "Epoch 40/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.6835 - val_loss: 54.4164 - lr: 1.0000e-05\n",
      "Epoch 41/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.3892 - val_loss: 47.5252 - lr: 1.0000e-05\n",
      "Epoch 42/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.2438 - val_loss: 50.7840 - lr: 1.0000e-05\n",
      "Epoch 43/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 51.2014 - val_loss: 53.5012 - lr: 1.0000e-05\n",
      "Epoch 44/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.0538 - val_loss: 47.9980 - lr: 1.0000e-05\n",
      "Epoch 45/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 50.2826 - val_loss: 54.9707 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "1350/1350 [==============================] - 81s 60ms/step - loss: 49.6915 - val_loss: 47.8887 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.6689 - val_loss: 55.0050 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.1713 - val_loss: 47.6581 - lr: 1.0000e-05\n",
      "Epoch 49/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.9591 - val_loss: 48.2939 - lr: 1.0000e-05\n",
      "Epoch 50/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.1964 - val_loss: 54.8166 - lr: 1.0000e-05\n",
      "Epoch 51/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.8979 - val_loss: 47.9574 - lr: 1.0000e-05\n",
      "Epoch 52/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.9688 - val_loss: 47.3493 - lr: 1.0000e-06\n",
      "Epoch 53/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 47.3363 - val_loss: 50.7061 - lr: 1.0000e-06\n",
      "Epoch 54/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 47.4444 - val_loss: 47.6901 - lr: 1.0000e-06\n",
      "Epoch 55/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.8146 - val_loss: 52.2358 - lr: 1.0000e-06\n",
      "Epoch 56/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.7766 - val_loss: 47.8859 - lr: 1.0000e-06\n",
      "Epoch 57/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 47.3848 - val_loss: 51.1812 - lr: 1.0000e-06\n",
      "Epoch 58/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.9800 - val_loss: 48.1582 - lr: 1.0000e-06\n",
      "Epoch 59/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 47.2786 - val_loss: 47.1732 - lr: 1.0000e-06\n",
      "Epoch 60/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.6261 - val_loss: 47.9176 - lr: 1.0000e-06\n",
      "Epoch 61/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 47.0636 - val_loss: 50.1455 - lr: 1.0000e-06\n",
      "Epoch 62/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 47.2160 - val_loss: 47.6669 - lr: 1.0000e-06\n",
      "Epoch 63/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 47.3093 - val_loss: 48.0777 - lr: 1.0000e-06\n",
      "Epoch 64/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 47.0544 - val_loss: 47.7820 - lr: 1.0000e-06\n",
      "Epoch 65/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.9030 - val_loss: 50.1586 - lr: 1.0000e-06\n",
      "Epoch 66/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.9613 - val_loss: 47.8148 - lr: 1.0000e-06\n",
      "Epoch 67/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.8922 - val_loss: 48.3953 - lr: 1.0000e-06\n",
      "Epoch 68/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.7632 - val_loss: 48.6114 - lr: 1.0000e-06\n",
      "Epoch 69/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.8679 - val_loss: 48.6813 - lr: 1.0000e-06\n",
      "Epoch 70/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.5682 - val_loss: 47.6739 - lr: 1.0000e-07\n",
      "Epoch 71/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.5582 - val_loss: 47.8983 - lr: 1.0000e-07\n",
      "Epoch 72/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.7383 - val_loss: 47.9979 - lr: 1.0000e-07\n",
      "Epoch 73/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.8449 - val_loss: 47.7199 - lr: 1.0000e-07\n",
      "Epoch 74/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.5848 - val_loss: 48.0897 - lr: 1.0000e-07\n",
      "Epoch 75/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.3563 - val_loss: 47.9998 - lr: 1.0000e-07\n",
      "Epoch 76/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.6386 - val_loss: 47.7971 - lr: 1.0000e-07\n",
      "Epoch 77/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.4887 - val_loss: 47.6228 - lr: 1.0000e-07\n",
      "Epoch 78/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.5869 - val_loss: 47.6183 - lr: 1.0000e-07\n",
      "Epoch 79/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 46.8574 - val_loss: 47.7371 - lr: 1.0000e-07\n",
      "Epoch 00079: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_ASS_1_fold_2021-01-18.h5\n",
      "模型已经被保存。\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 1571.4449 - val_loss: 5377.4551 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 784.3474 - val_loss: 1456.4207 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 788.7210 - val_loss: 2595.7275 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 727.9020 - val_loss: 1420.5925 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 680.4835 - val_loss: 447.1873 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 649.9695 - val_loss: 483.8163 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 611.7859 - val_loss: 1943.0692 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 589.6587 - val_loss: 1026.1401 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 578.8672 - val_loss: 302.0519 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 591.2199 - val_loss: 395.2875 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 534.0367 - val_loss: 1071.3580 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 562.4349 - val_loss: 1118.9880 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 487.5915 - val_loss: 705.2781 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 466.6742 - val_loss: 243.9125 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 497.0211 - val_loss: 171.5075 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 480.2106 - val_loss: 254.1982 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 424.3336 - val_loss: 2599.6743 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 443.2261 - val_loss: 388.0315 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 441.8492 - val_loss: 1004.3116 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 420.5754 - val_loss: 182.3415 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 438.9345 - val_loss: 651.6062 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 419.5980 - val_loss: 1130.1117 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 402.3517 - val_loss: 239.5481 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 390.3446 - val_loss: 977.3083 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 363.4016 - val_loss: 1807.7228 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 191.4075 - val_loss: 145.1891 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 193.1344 - val_loss: 395.5125 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 182.8629 - val_loss: 191.8238 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 177.1190 - val_loss: 486.3318 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 170.1529 - val_loss: 303.9919 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 174.7729 - val_loss: 116.3902 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 166.5506 - val_loss: 116.4461 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 171.2563 - val_loss: 117.2168 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 167.0455 - val_loss: 136.9413 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 163.0197 - val_loss: 165.0105 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 164.9984 - val_loss: 144.4820 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 156.7900 - val_loss: 163.9433 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 164.9300 - val_loss: 109.7528 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 160.4279 - val_loss: 111.4134 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 161.2913 - val_loss: 355.4121 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 168.2055 - val_loss: 125.1690 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 160.8098 - val_loss: 349.8495 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 156.2727 - val_loss: 260.9599 - lr: 1.0000e-04\n",
      "Epoch 44/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 158.5259 - val_loss: 154.3039 - lr: 1.0000e-04\n",
      "Epoch 45/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 154.0029 - val_loss: 118.6293 - lr: 1.0000e-04\n",
      "Epoch 46/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 154.1618 - val_loss: 119.2179 - lr: 1.0000e-04\n",
      "Epoch 47/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 155.2613 - val_loss: 107.9774 - lr: 1.0000e-04\n",
      "Epoch 48/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 148.0559 - val_loss: 132.6112 - lr: 1.0000e-04\n",
      "Epoch 49/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 147.2833 - val_loss: 258.1993 - lr: 1.0000e-04\n",
      "Epoch 50/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 148.3389 - val_loss: 104.2707 - lr: 1.0000e-04\n",
      "Epoch 51/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 150.0536 - val_loss: 126.1109 - lr: 1.0000e-04\n",
      "Epoch 52/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 147.5181 - val_loss: 359.5459 - lr: 1.0000e-04\n",
      "Epoch 53/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 149.2988 - val_loss: 213.9142 - lr: 1.0000e-04\n",
      "Epoch 54/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 145.0356 - val_loss: 162.9825 - lr: 1.0000e-04\n",
      "Epoch 55/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 146.8588 - val_loss: 168.7914 - lr: 1.0000e-04\n",
      "Epoch 56/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 150.5493 - val_loss: 108.5295 - lr: 1.0000e-04\n",
      "Epoch 57/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 149.3296 - val_loss: 246.3616 - lr: 1.0000e-04\n",
      "Epoch 58/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 140.9845 - val_loss: 107.5347 - lr: 1.0000e-04\n",
      "Epoch 59/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 141.8413 - val_loss: 215.9280 - lr: 1.0000e-04\n",
      "Epoch 60/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 139.1613 - val_loss: 138.1505 - lr: 1.0000e-04\n",
      "Epoch 61/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 118.2828 - val_loss: 119.4881 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 116.4916 - val_loss: 109.4530 - lr: 1.0000e-05\n",
      "Epoch 63/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 116.9269 - val_loss: 100.8592 - lr: 1.0000e-05\n",
      "Epoch 64/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 113.9039 - val_loss: 100.4165 - lr: 1.0000e-05\n",
      "Epoch 65/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 114.7547 - val_loss: 106.0970 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 115.7547 - val_loss: 104.6102 - lr: 1.0000e-05\n",
      "Epoch 67/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 114.0134 - val_loss: 100.7628 - lr: 1.0000e-05\n",
      "Epoch 68/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 113.0569 - val_loss: 107.6029 - lr: 1.0000e-05\n",
      "Epoch 69/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 113.8068 - val_loss: 122.6870 - lr: 1.0000e-05\n",
      "Epoch 70/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 114.2931 - val_loss: 104.5200 - lr: 1.0000e-05\n",
      "Epoch 71/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 114.1181 - val_loss: 111.2664 - lr: 1.0000e-05\n",
      "Epoch 72/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.4044 - val_loss: 100.7039 - lr: 1.0000e-05\n",
      "Epoch 73/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 113.2720 - val_loss: 114.3774 - lr: 1.0000e-05\n",
      "Epoch 74/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.9819 - val_loss: 104.0234 - lr: 1.0000e-05\n",
      "Epoch 75/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.7516 - val_loss: 101.4405 - lr: 1.0000e-06\n",
      "Epoch 76/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.9472 - val_loss: 102.5055 - lr: 1.0000e-06\n",
      "Epoch 77/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.5587 - val_loss: 103.9501 - lr: 1.0000e-06\n",
      "Epoch 78/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.7758 - val_loss: 100.8125 - lr: 1.0000e-06\n",
      "Epoch 79/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.5117 - val_loss: 101.4265 - lr: 1.0000e-06\n",
      "Epoch 80/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.3742 - val_loss: 102.6842 - lr: 1.0000e-06\n",
      "Epoch 81/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.3086 - val_loss: 102.1989 - lr: 1.0000e-06\n",
      "Epoch 82/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.1585 - val_loss: 100.2677 - lr: 1.0000e-06\n",
      "Epoch 83/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.0082 - val_loss: 105.7607 - lr: 1.0000e-06\n",
      "Epoch 84/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.9893 - val_loss: 100.3692 - lr: 1.0000e-06\n",
      "Epoch 85/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.4540 - val_loss: 99.9846 - lr: 1.0000e-06\n",
      "Epoch 86/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.5778 - val_loss: 102.5397 - lr: 1.0000e-06\n",
      "Epoch 87/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.9064 - val_loss: 100.2098 - lr: 1.0000e-06\n",
      "Epoch 88/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.7945 - val_loss: 102.5038 - lr: 1.0000e-06\n",
      "Epoch 89/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.7217 - val_loss: 101.6251 - lr: 1.0000e-06\n",
      "Epoch 90/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.7671 - val_loss: 102.8113 - lr: 1.0000e-06\n",
      "Epoch 91/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.8811 - val_loss: 100.4607 - lr: 1.0000e-06\n",
      "Epoch 92/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.3182 - val_loss: 100.2062 - lr: 1.0000e-06\n",
      "Epoch 93/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.7575 - val_loss: 101.7431 - lr: 1.0000e-06\n",
      "Epoch 94/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.8175 - val_loss: 102.5376 - lr: 1.0000e-06\n",
      "Epoch 95/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.1026 - val_loss: 103.9981 - lr: 1.0000e-06\n",
      "Epoch 96/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.6762 - val_loss: 101.0797 - lr: 1.0000e-07\n",
      "Epoch 97/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.2900 - val_loss: 101.7595 - lr: 1.0000e-07\n",
      "Epoch 98/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 107.2265 - val_loss: 101.3314 - lr: 1.0000e-07\n",
      "Epoch 99/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 107.3464 - val_loss: 101.2823 - lr: 1.0000e-07\n",
      "Epoch 100/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.4570 - val_loss: 101.3032 - lr: 1.0000e-07\n",
      "Epoch 101/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.5736 - val_loss: 101.1705 - lr: 1.0000e-07\n",
      "Epoch 102/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.3907 - val_loss: 101.4607 - lr: 1.0000e-07\n",
      "Epoch 103/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 107.8191 - val_loss: 101.6221 - lr: 1.0000e-07\n",
      "Epoch 104/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 108.9825 - val_loss: 100.7878 - lr: 1.0000e-07\n",
      "Epoch 105/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 107.8110 - val_loss: 101.7214 - lr: 1.0000e-07\n",
      "Epoch 00105: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_Pin_1_fold_2021-01-18.h5\n",
      "模型已经被保存。\n",
      "fold 2\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6716 - val_loss: 37.6840 - lr: 1.0000e-08\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.1138 - val_loss: 37.9019 - lr: 1.0000e-08\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6692 - val_loss: 37.1361 - lr: 1.0000e-08\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5934 - val_loss: 38.1763 - lr: 1.0000e-08\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9009 - val_loss: 37.9420 - lr: 1.0000e-08\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.5185 - val_loss: 38.2666 - lr: 1.0000e-08\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5117 - val_loss: 37.9122 - lr: 1.0000e-08\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8533 - val_loss: 37.8575 - lr: 1.0000e-08\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.0007 - val_loss: 37.8718 - lr: 1.0000e-08\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6197 - val_loss: 38.4534 - lr: 1.0000e-08\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.5574 - val_loss: 38.3807 - lr: 1.0000e-08\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6358 - val_loss: 37.6859 - lr: 1.0000e-08\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6625 - val_loss: 37.9611 - lr: 1.0000e-08\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6885 - val_loss: 37.4886 - lr: 1.0000e-09\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.5723 - val_loss: 38.0833 - lr: 1.0000e-09\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8337 - val_loss: 37.6057 - lr: 1.0000e-09\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.1520 - val_loss: 37.5509 - lr: 1.0000e-09\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8261 - val_loss: 37.7371 - lr: 1.0000e-09\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5772 - val_loss: 38.0652 - lr: 1.0000e-09\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5004 - val_loss: 37.9115 - lr: 1.0000e-09\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9340 - val_loss: 37.4082 - lr: 1.0000e-09\n",
      "Epoch 22/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6086 - val_loss: 37.9172 - lr: 1.0000e-09\n",
      "Epoch 23/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.0143 - val_loss: 37.9578 - lr: 1.0000e-09\n",
      "Epoch 00023: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_ASS_2_fold_2021-01-18.h5\n",
      "模型已经被保存。\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0279 - val_loss: 89.2278 - lr: 1.0000e-08\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0403 - val_loss: 91.4128 - lr: 1.0000e-08\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.5489 - val_loss: 89.0287 - lr: 1.0000e-08\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.8236 - val_loss: 89.4311 - lr: 1.0000e-08\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0641 - val_loss: 90.5034 - lr: 1.0000e-08\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.3024 - val_loss: 89.2385 - lr: 1.0000e-08\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.4154 - val_loss: 90.9545 - lr: 1.0000e-08\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.0666 - val_loss: 91.0986 - lr: 1.0000e-08\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.7341 - val_loss: 89.8835 - lr: 1.0000e-08\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.4510 - val_loss: 89.4799 - lr: 1.0000e-08\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.6048 - val_loss: 89.7267 - lr: 1.0000e-08\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.2495 - val_loss: 90.8616 - lr: 1.0000e-08\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.7322 - val_loss: 90.3546 - lr: 1.0000e-08\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.9357 - val_loss: 88.9135 - lr: 1.0000e-09\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3455 - val_loss: 89.8704 - lr: 1.0000e-09\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.4423 - val_loss: 90.3321 - lr: 1.0000e-09\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.3786 - val_loss: 90.3655 - lr: 1.0000e-09\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.1272 - val_loss: 90.3978 - lr: 1.0000e-09\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.0204 - val_loss: 89.9877 - lr: 1.0000e-09\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.2763 - val_loss: 90.7577 - lr: 1.0000e-09\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.5904 - val_loss: 89.9940 - lr: 1.0000e-09\n",
      "Epoch 22/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.7428 - val_loss: 89.9671 - lr: 1.0000e-09\n",
      "Epoch 23/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0740 - val_loss: 89.3082 - lr: 1.0000e-09\n",
      "Epoch 24/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.4835 - val_loss: 90.9438 - lr: 1.0000e-09\n",
      "Epoch 25/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3132 - val_loss: 89.3443 - lr: 1.0000e-10\n",
      "Epoch 26/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.5263 - val_loss: 89.5874 - lr: 1.0000e-10\n",
      "Epoch 27/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3073 - val_loss: 89.9472 - lr: 1.0000e-10\n",
      "Epoch 28/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.5066 - val_loss: 89.3765 - lr: 1.0000e-10\n",
      "Epoch 29/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.6719 - val_loss: 90.8411 - lr: 1.0000e-10\n",
      "Epoch 30/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.1485 - val_loss: 89.9443 - lr: 1.0000e-10\n",
      "Epoch 31/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.2042 - val_loss: 90.9792 - lr: 1.0000e-10\n",
      "Epoch 32/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.5302 - val_loss: 89.3576 - lr: 1.0000e-10\n",
      "Epoch 33/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.6711 - val_loss: 91.1231 - lr: 1.0000e-10\n",
      "Epoch 34/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.8554 - val_loss: 89.4234 - lr: 1.0000e-10\n",
      "Epoch 00034: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_Pin_2_fold_2021-01-18.h5\n",
      "模型已经被保存。\n",
      "fold 3\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7396 - val_loss: 37.5118 - lr: 1.0000e-10\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.3466 - val_loss: 37.6999 - lr: 1.0000e-10\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5793 - val_loss: 37.4051 - lr: 1.0000e-10\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5718 - val_loss: 37.8703 - lr: 1.0000e-10\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6586 - val_loss: 38.2041 - lr: 1.0000e-10\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9027 - val_loss: 37.9283 - lr: 1.0000e-10\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9669 - val_loss: 37.6715 - lr: 1.0000e-10\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9161 - val_loss: 37.3830 - lr: 1.0000e-10\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9438 - val_loss: 37.8753 - lr: 1.0000e-10\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6808 - val_loss: 38.3393 - lr: 1.0000e-10\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6777 - val_loss: 38.1437 - lr: 1.0000e-10\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7709 - val_loss: 38.0155 - lr: 1.0000e-10\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6303 - val_loss: 38.2564 - lr: 1.0000e-10\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9010 - val_loss: 38.0266 - lr: 1.0000e-10\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8117 - val_loss: 37.5878 - lr: 1.0000e-10\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5255 - val_loss: 37.7091 - lr: 1.0000e-10\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7754 - val_loss: 37.7229 - lr: 1.0000e-10\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6821 - val_loss: 37.5874 - lr: 1.0000e-10\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5939 - val_loss: 38.0440 - lr: 1.0000e-11\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6112 - val_loss: 38.1456 - lr: 1.0000e-11\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9042 - val_loss: 38.3693 - lr: 1.0000e-11\n",
      "Epoch 22/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8100 - val_loss: 38.1185 - lr: 1.0000e-11\n",
      "Epoch 23/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8857 - val_loss: 38.2523 - lr: 1.0000e-11\n",
      "Epoch 24/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.4604 - val_loss: 37.5958 - lr: 1.0000e-11\n",
      "Epoch 25/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6991 - val_loss: 38.0172 - lr: 1.0000e-11\n",
      "Epoch 26/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.2743 - val_loss: 37.9467 - lr: 1.0000e-11\n",
      "Epoch 27/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.4797 - val_loss: 38.1921 - lr: 1.0000e-11\n",
      "Epoch 28/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8288 - val_loss: 37.6905 - lr: 1.0000e-11\n",
      "Epoch 00028: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_ASS_3_fold_2021-01-18.h5\n",
      "模型已经被保存。\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.2665 - val_loss: 87.0164 - lr: 1.0000e-11\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.8365 - val_loss: 88.4281 - lr: 1.0000e-11\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3724 - val_loss: 87.8581 - lr: 1.0000e-11\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.8076 - val_loss: 88.4518 - lr: 1.0000e-11\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.5400 - val_loss: 87.6303 - lr: 1.0000e-11\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.8903 - val_loss: 87.4186 - lr: 1.0000e-11\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.9648 - val_loss: 87.1963 - lr: 1.0000e-11\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.6019 - val_loss: 89.6039 - lr: 1.0000e-11\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.5333 - val_loss: 88.0714 - lr: 1.0000e-11\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.6970 - val_loss: 87.7821 - lr: 1.0000e-11\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.1148 - val_loss: 87.6988 - lr: 1.0000e-11\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.3833 - val_loss: 86.4425 - lr: 1.0000e-12\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.2037 - val_loss: 87.8850 - lr: 1.0000e-12\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.9345 - val_loss: 89.1039 - lr: 1.0000e-12\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.6892 - val_loss: 88.8903 - lr: 1.0000e-12\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.6393 - val_loss: 87.1493 - lr: 1.0000e-12\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.6617 - val_loss: 87.9214 - lr: 1.0000e-12\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.9522 - val_loss: 87.8074 - lr: 1.0000e-12\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.9140 - val_loss: 89.0007 - lr: 1.0000e-12\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3717 - val_loss: 87.7200 - lr: 1.0000e-12\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3203 - val_loss: 89.7707 - lr: 1.0000e-12\n",
      "Epoch 22/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.5842 - val_loss: 87.5217 - lr: 1.0000e-12\n",
      "Epoch 23/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.8819 - val_loss: 87.0616 - lr: 1.0000e-13\n",
      "Epoch 24/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.0053 - val_loss: 88.0116 - lr: 1.0000e-13\n",
      "Epoch 25/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0984 - val_loss: 87.3202 - lr: 1.0000e-13\n",
      "Epoch 26/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.9976 - val_loss: 88.5935 - lr: 1.0000e-13\n",
      "Epoch 27/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.6179 - val_loss: 87.4287 - lr: 1.0000e-13\n",
      "Epoch 28/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.7986 - val_loss: 88.4605 - lr: 1.0000e-13\n",
      "Epoch 29/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.7472 - val_loss: 88.1809 - lr: 1.0000e-13\n",
      "Epoch 30/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.8075 - val_loss: 87.6157 - lr: 1.0000e-13\n",
      "Epoch 31/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3642 - val_loss: 88.3139 - lr: 1.0000e-13\n",
      "Epoch 32/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 113.2536 - val_loss: 88.7283 - lr: 1.0000e-13\n",
      "Epoch 00032: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_Pin_3_fold_2021-01-18.h5\n",
      "模型已经被保存。\n",
      "fold 4\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.4776 - val_loss: 37.5783 - lr: 1.0000e-12\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.2807 - val_loss: 37.9413 - lr: 1.0000e-12\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7401 - val_loss: 38.6893 - lr: 1.0000e-12\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6129 - val_loss: 37.8950 - lr: 1.0000e-12\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.2263 - val_loss: 38.3108 - lr: 1.0000e-12\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7111 - val_loss: 37.9055 - lr: 1.0000e-12\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7592 - val_loss: 38.0288 - lr: 1.0000e-12\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.3797 - val_loss: 37.8711 - lr: 1.0000e-12\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6042 - val_loss: 37.7186 - lr: 1.0000e-12\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.0352 - val_loss: 38.0686 - lr: 1.0000e-12\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.5689 - val_loss: 37.6147 - lr: 1.0000e-12\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8476 - val_loss: 38.6485 - lr: 1.0000e-13\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.4899 - val_loss: 38.0469 - lr: 1.0000e-13\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6245 - val_loss: 38.0242 - lr: 1.0000e-13\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9342 - val_loss: 37.7454 - lr: 1.0000e-13\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5615 - val_loss: 38.0067 - lr: 1.0000e-13\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7217 - val_loss: 38.2440 - lr: 1.0000e-13\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9810 - val_loss: 38.2218 - lr: 1.0000e-13\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5331 - val_loss: 38.1643 - lr: 1.0000e-13\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.9769 - val_loss: 37.8832 - lr: 1.0000e-13\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6941 - val_loss: 38.5855 - lr: 1.0000e-13\n",
      "Epoch 00021: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_ASS_4_fold_2021-01-18.h5\n",
      "模型已经被保存。\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.2644 - val_loss: 89.3962 - lr: 1.0000e-14\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3154 - val_loss: 89.0200 - lr: 1.0000e-14\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.6963 - val_loss: 89.6780 - lr: 1.0000e-14\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.0333 - val_loss: 90.7917 - lr: 1.0000e-14\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.9836 - val_loss: 89.6393 - lr: 1.0000e-14\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.1453 - val_loss: 90.6880 - lr: 1.0000e-14\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0554 - val_loss: 90.2311 - lr: 1.0000e-14\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.1906 - val_loss: 88.8995 - lr: 1.0000e-14\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.9295 - val_loss: 89.2485 - lr: 1.0000e-14\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.6701 - val_loss: 90.7973 - lr: 1.0000e-14\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3890 - val_loss: 89.3279 - lr: 1.0000e-14\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.2188 - val_loss: 88.8489 - lr: 1.0000e-14\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.7644 - val_loss: 90.2142 - lr: 1.0000e-14\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.3064 - val_loss: 89.4347 - lr: 1.0000e-14\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.8643 - val_loss: 90.4060 - lr: 1.0000e-14\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.1936 - val_loss: 88.8655 - lr: 1.0000e-14\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.2971 - val_loss: 89.1186 - lr: 1.0000e-14\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 112.1357 - val_loss: 90.0904 - lr: 1.0000e-14\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.4701 - val_loss: 89.7742 - lr: 1.0000e-14\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.0094 - val_loss: 89.6293 - lr: 1.0000e-14\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0994 - val_loss: 89.1217 - lr: 1.0000e-14\n",
      "Epoch 22/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0724 - val_loss: 88.5144 - lr: 1.0000e-14\n",
      "Epoch 23/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.9204 - val_loss: 89.9036 - lr: 1.0000e-14\n",
      "Epoch 24/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.1050 - val_loss: 90.4649 - lr: 1.0000e-14\n",
      "Epoch 25/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.9695 - val_loss: 89.8828 - lr: 1.0000e-14\n",
      "Epoch 26/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.8464 - val_loss: 89.5895 - lr: 1.0000e-14\n",
      "Epoch 27/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.6746 - val_loss: 88.8426 - lr: 1.0000e-14\n",
      "Epoch 28/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.4819 - val_loss: 89.8855 - lr: 1.0000e-14\n",
      "Epoch 29/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 109.5955 - val_loss: 88.8855 - lr: 1.0000e-14\n",
      "Epoch 30/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.0502 - val_loss: 89.9834 - lr: 1.0000e-14\n",
      "Epoch 31/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.1990 - val_loss: 89.6026 - lr: 1.0000e-14\n",
      "Epoch 32/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.7020 - val_loss: 89.3697 - lr: 1.0000e-14\n",
      "Epoch 33/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.0642 - val_loss: 89.7825 - lr: 1.0000e-15\n",
      "Epoch 34/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.7098 - val_loss: 89.8900 - lr: 1.0000e-15\n",
      "Epoch 35/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.8232 - val_loss: 88.8198 - lr: 1.0000e-15\n",
      "Epoch 36/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.2804 - val_loss: 90.7040 - lr: 1.0000e-15\n",
      "Epoch 37/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.1770 - val_loss: 89.6883 - lr: 1.0000e-15\n",
      "Epoch 38/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.8267 - val_loss: 90.0185 - lr: 1.0000e-15\n",
      "Epoch 39/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.1889 - val_loss: 89.7236 - lr: 1.0000e-15\n",
      "Epoch 40/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.6955 - val_loss: 89.6161 - lr: 1.0000e-15\n",
      "Epoch 41/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 110.4685 - val_loss: 89.1441 - lr: 1.0000e-15\n",
      "Epoch 42/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 111.1182 - val_loss: 89.1794 - lr: 1.0000e-15\n",
      "Epoch 00042: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_Pin_4_fold_2021-01-18.h5\n",
      "模型已经被保存。\n",
      "fold 5\n",
      "Epoch 1/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.4024 - val_loss: 38.4010 - lr: 1.0000e-14\n",
      "Epoch 2/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6912 - val_loss: 37.8108 - lr: 1.0000e-14\n",
      "Epoch 3/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.4037 - val_loss: 37.6494 - lr: 1.0000e-14\n",
      "Epoch 4/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8404 - val_loss: 38.4453 - lr: 1.0000e-14\n",
      "Epoch 5/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7138 - val_loss: 37.6182 - lr: 1.0000e-14\n",
      "Epoch 6/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5289 - val_loss: 38.0362 - lr: 1.0000e-14\n",
      "Epoch 7/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6980 - val_loss: 38.6197 - lr: 1.0000e-14\n",
      "Epoch 8/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.9965 - val_loss: 37.5458 - lr: 1.0000e-14\n",
      "Epoch 9/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6442 - val_loss: 37.8789 - lr: 1.0000e-14\n",
      "Epoch 10/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.4356 - val_loss: 38.6295 - lr: 1.0000e-14\n",
      "Epoch 11/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.5591 - val_loss: 37.5612 - lr: 1.0000e-14\n",
      "Epoch 12/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.5624 - val_loss: 38.5389 - lr: 1.0000e-14\n",
      "Epoch 13/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7684 - val_loss: 37.9702 - lr: 1.0000e-14\n",
      "Epoch 14/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.2961 - val_loss: 38.2282 - lr: 1.0000e-14\n",
      "Epoch 15/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7973 - val_loss: 38.0999 - lr: 1.0000e-14\n",
      "Epoch 16/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.3603 - val_loss: 37.9405 - lr: 1.0000e-14\n",
      "Epoch 17/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7618 - val_loss: 37.7709 - lr: 1.0000e-14\n",
      "Epoch 18/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7094 - val_loss: 37.9166 - lr: 1.0000e-14\n",
      "Epoch 19/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.2744 - val_loss: 38.5994 - lr: 1.0000e-15\n",
      "Epoch 20/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.0660 - val_loss: 37.3949 - lr: 1.0000e-15\n",
      "Epoch 21/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6807 - val_loss: 37.7303 - lr: 1.0000e-15\n",
      "Epoch 22/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7163 - val_loss: 38.3324 - lr: 1.0000e-15\n",
      "Epoch 23/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8132 - val_loss: 38.8538 - lr: 1.0000e-15\n",
      "Epoch 24/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8170 - val_loss: 38.5328 - lr: 1.0000e-15\n",
      "Epoch 25/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.3407 - val_loss: 37.7906 - lr: 1.0000e-15\n",
      "Epoch 26/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7080 - val_loss: 38.2540 - lr: 1.0000e-15\n",
      "Epoch 27/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8561 - val_loss: 37.8412 - lr: 1.0000e-15\n",
      "Epoch 28/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.4720 - val_loss: 37.5974 - lr: 1.0000e-15\n",
      "Epoch 29/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7095 - val_loss: 37.7852 - lr: 1.0000e-15\n",
      "Epoch 30/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.6064 - val_loss: 38.0766 - lr: 1.0000e-15\n",
      "Epoch 31/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.6330 - val_loss: 37.8908 - lr: 1.0000e-16\n",
      "Epoch 32/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.0485 - val_loss: 37.8769 - lr: 1.0000e-16\n",
      "Epoch 33/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.4068 - val_loss: 37.5157 - lr: 1.0000e-16\n",
      "Epoch 34/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8980 - val_loss: 38.1612 - lr: 1.0000e-16\n",
      "Epoch 35/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.7778 - val_loss: 37.7497 - lr: 1.0000e-16\n",
      "Epoch 36/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8399 - val_loss: 38.1384 - lr: 1.0000e-16\n",
      "Epoch 37/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8015 - val_loss: 38.1146 - lr: 1.0000e-16\n",
      "Epoch 38/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 49.1025 - val_loss: 38.2550 - lr: 1.0000e-16\n",
      "Epoch 39/300\n",
      "1350/1350 [==============================] - 80s 59ms/step - loss: 48.5953 - val_loss: 37.9555 - lr: 1.0000e-16\n",
      "Epoch 40/300\n",
      "1350/1350 [==============================] - 79s 59ms/step - loss: 48.8328 - val_loss: 37.8970 - lr: 1.0000e-16\n",
      "Epoch 00040: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 16)        208       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 16)        1040      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 16)        4112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 16)        16400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        16416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 30, 30, 32)        65568     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 30, 30, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 64)        8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 30, 30, 64)        65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 30, 30, 64)        262208    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 57600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              57601000  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               100100    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 58,274,097\n",
      "Trainable params: 58,272,753\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoTUlEQVR4nO3deXhc1X3/8feZGa2jXbJkWbItyStggY2EwVCMTAIOhMSEJJSwxEloaJOWZmko0PyaPb+Q0Cbt04df0jRJcRpS280GDYSEGAnjYPCG992yLSQvWqxtJGubOb8/7kiWbMmSRpJHFz6v57nPnbkz9853ztz7uWfOjDTGWouIiLiPJ9oFiIhIZBTgIiIupQAXEXEpBbiIiEspwEVEXMp3KR8sKyvLFhQURLRuW1sbfr9/fAsaJ6otMqotMqotMm6ubevWrfXW2ikX3GCtvWRTSUmJjVR5eXnE60401RYZ1RYZ1RYZN9cGbLGDZKqGUEREXEoBLiLiUgpwERGXGtGHmMaYY0ArEAR6rLWlxpgMYA1QABwD7rbWNk5MmSIicr7R9MCXWWsXWmtLw9cfA9ZZa+cA68LXRUTkEhnLEMoKYFX48irgzjFXIyIiI2bsCP4boTHmKNAIWODfrbU/NMY0WWvT+t2n0VqbPsi6DwEPAeTk5JSsXr06okIDgQBJSUkRrTvRVFtkVFtkVFtk3FzbsmXLtvYb/ThnsO8Wnj8B08LzbGAHsBRoOu8+jcNtR98DH1873mq0/7mh0tY0tg95H7VbZFRbZFRbZCL9HviIPsS01p4Iz2uNMb8GFgOnjTG51tqTxphcoHYUJxyJUHtXD89tP8Ezb1Sxq6YZgG88v487rszlL24sYkFe6oQ+/vGGNl49VM+GQ/Vsq2qkIMvP9bMyWVKUycIZacT5vBP6+BfT0R1k09EzlB+oZeORBhJivUxNiScnJZ7c1HimpsYzNcWZ56TEEx8TvVrFPUIhy8mWDpLifKQmxES7nAGGDXBjjB/wWGtbw5dvBb4GPAesBJ4Iz5+dyEInirWWukAnsV4PyfExeD1mQh/rdEsnlXUBjtS3caQ2wPGGNtISY5k/NZn5uSlclpvMlKQ4jBlYx/5TLfz8jSp+va2G1s4e5uUk87UVV7C4MIO1m6tZs7mK32w/wZKiTD65tJCyudl4xuG5NLd389qRel497IR21Zl2AKalxnNdUSaV9QH+dd0h/uWPh4iP8VA6M4MlszJZMiuTK/NS8Xkn9puq1Y3tVByoo+JALX863MDZ7iBxPg+LCzOwFg6ebmX9wTrauoID1jMGirL8FOelsiA8XTEtheT4sR+goZClJ+QMTVrODVH2jlYaw7if6IIhS8vZbs60dxHn85CXlnDBPnSpdfYE2Xeyle1VjeyobmbHW02ErGX5FVO5rTiXq/JTR1xjfaCTbccbsUBKfAwpCb7wPIbkON+g+3ooZOnsCdHZE6SzJ0T92RCnmjvweQ0xHg8+r+m77PEY2jp7OFrfxpG6AEfq2pzjtK6No/UBOrpDeAwU56WyZFYWN8zOpHRmBgmxw7+OoZCTMakJMePeaRhJDzwH+HW4oX3Az621LxpjNgNrjTEPAlXAh8e1smF0dAc51tDG0bo2Kuvb8BhDYZafoil+ZmQkDtlQHd1BdtU0s/V4I9uON7Ktqon6QGff7clxPlISnB0jNbyTpCXGMCU5jilJcWSnxPddnpIchz/OacJgyNLY3kVDoIuGQCf1beF5oJPqxrMcqQtwtK5tQJAkxnopyPSz/1Qrv36zpm95pj+W+bnJzJ+aQm5qPC/uPsWW443E+jzcUZzLfdfN4OoZ6X07/5fedzmfefccVm+q4unXjvGJp7cwa4qfv7ixiMxg79stZ9u9cWKtEy2Bjh5OtXRwqqWD083heUsHp5o7ONncwcHTrYQs+GO9LJmVyYN/VsifzcmiKMvf9/jN7d28cbSB14408HplA0/+/gDgrLNwRhpXz0jn6pnpXD09ndTEoQPyVHMHO6ub2FndzM6aZhoCncT6PMR6PcT6PMT5nHmM14PP42FXTRMHTwcAmJ6RwN2l+ZTNz2ZJUeYFr39rRzenW5zndKq5g7caz7L3RAuvV57hN9tP9N2vMMvPgrxUTKCLrV0H6A5aeoIhekKWnlCInqATzh3dQdo6e2jrDNLW1UNbZw+BTmfZ2e6BJ4vBFGQmcm1hJosLM7i2KIP89MSL3r+2tYO9J1rYe7KFjbs6+dnxzTS2d9PY1kVjexdNZ7v7XmOAtMQYFkxL5Yq8FOckNS2VGRmJA4IuFLLUtnZS09ROdeNZaprOcqq5A6/HkBTnIynOhz/OR3K8D3+sj6R4H4mxXqyFnpAlZC09wfA8ZAmFLK/VdFP+7G62Vzez70QLXcEQANnJcSycnkZnT4gfbzjKv6+vJC8tgdsWOGG+aHragNrOtHXxRmUDGyudfar3dR5KcrjWnlCIzu4QnT2hvsce4JV1g67vMRCyA69Pz0ikKMvPDbMyKZzip7alk41HGvjxhkp+8MoRYr0eFs1I4/pZWSyZlUnIWqcdG89S09ROTZNz+URTB13BEP/14GJunHPhvzMZixF9iDleSktL7ZYtW0a93o63mlizbjPetFyO1rdxtL6NmqazQ97fGMhLS6Awy09hlhPoNU1n2VbVxN4TzXQHnedckJnI1TPSKc5PxVpoPttNS0e3Mz/bTcvZHprPdjvB3NZFMHRhW/ljvXgI0tY9cAfo5fUYpqbEMys7iaIsP7Om+CmaksSsKUnkpJzraTe1d7H/VCv7T7aw/1Qr+062cOB0Kx3dIYqy/Nx77Qw+eHU+6f7Yi7ZVdzDE8ztP8h+vVrLnRMsoWvmcrKRYclKc4YYrpqVw49wpLJyeRswIe9MNgU5erzzDG0cb2FbVyL6TrX1tN2uKn5KZ6Vw9I51Txw7izZzJjupmdlY3Udva2ddmc3OSyU2Npyt8IHb1hAZc7g6GKMzyc/P8bMrmZTNrij/iHmddaye7TzSzp6aZXTXN7K5poabpLB4Dvt6emsfg83rweQwx4ROKP87rBFs4PPxxPvyxXvxxPmJ9g7eVMdDdY9lV08Smo2do6egBnP312sIMFhdmcMW0VI6faWPPiZa+0K5rPdfJSIsz5GYkk+GPIS0xlozEWNITw5f9sbR29rCnppndJ5o5cKq1b39PjvdxeW4KXo+hpuksJ5rO9t3WKyXe55zYO3uINBoSY70U56WycEYaC/PTWDgjjakp8QNO+C/tO83vdp3k1UP1dAVDTE2J5z0LpgLwemUD+0+19m2rtCCD64oyuLYwgzifl5aOblo7epxjNDxv7egh0NmNz+sh3uclLsY54cf5vMT5PMTHeDl86ACz58yjJxQacGLuDjon5oRYr3OMZicxMzNxyHdJ7V09bD7WyGuH63ntSAO7TzRf0FbZyXHkpSeQl5ZAXnoC+WkJ3HxZDnlpCYNus6KigrKysiHb1Bgz6IeYrgjwLz+7m1Ubj5Mc76NoihOEhf2mgiw/1lqO1bdTWR/oC/mj9U4PvbWzh/gYD1fmp/WFx6IZaWQlxY24hlC4h13b2kld7xTopLalk8qqt7hyTgGZSXFkJcWRmRRLVlIsmf44UhNiIh7KCIYsta0dA3b+kbLWsrGygbXl2+j9D5AGZxu9mzJAYpwvPC4cR05KPNnJ8UOGT6Tau3rY8VYz26p63/U00tje3VdLUZafK/PTuDI/lSvzU7k8N3VEb00n0svl5dy8bNmEPkYoZNl/qpVNRxvYdOwMb1SeoaGtq+92n8cwJyeZy3NTuHxaijPPTeHNTX+66MHeX1dPiIOnW9kdDvTdNS14DOSlJw4Il96w6X1Haa3lbHeQQEcPrZ3hdxgdPbR3BfF4wGMMPo8Hj8c5yXnDy/bufJN7bl824qHIlo5uXt5Xywu7TlJxsA6PgWsKMriuKJPrijK5Mj91xB2H4QwXkpFqau9i6/FG4nxe8tITyE0d/ecrkQb4Jf13spH665tnU5JQx/tuKbtokBXnp1KcP/BDPGstje3dJMf7xrQjeDyGzKQ4MpPiuCx34G0VFbWUlc2LeNtD8XoMuamDn7GHY4zh+llZdL0VS1nZ3HGubHQSY3194+LgvCbHGtr5w/rXuff2peMy7jzePJdg/NjjMU4wT0vhYzcUYq3lSF0bB061MjMzkTk5SWMeK4/1efrG+EfDGENirI/EWB/Zo1ivudIzqs+RUuJjuHNRHncuyqOjO4jHmHHvQEy0tMRY3nVZTlQe2xUBnp0cT0qsiegtsjGGjGGGHeTSMuHPK+ZleCdleEeLMYbZ2UnMzp6c31WeaPpW0Oi561QnIiJ9FOAiIi6lABcRcSkFuIiISynARURcSgEuIuJSCnAREZdSgIuIuJQCXETEpRTgIiIupQAXEXEpBbiIiEspwEVEXEoBLiLiUgpwERGXUoCLiLiUAlxExKUU4CIiLqUAFxFxKQW4iIhLKcBFRFxKAS4i4lIKcBERl1KAi4i4lAJcRMSlFOAiIi6lABcRcSkFuIiIS404wI0xXmPMm8aY34avZxhjXjLGHArP0yeuTBEROd9oeuCfAfb1u/4YsM5aOwdYF74uIiKXyIgC3BiTD7wX+FG/xSuAVeHLq4A7x7UyERG5KGOtHf5OxvwC+BaQDHzBWnuHMabJWpvW7z6N1toLhlGMMQ8BDwHk5OSUrF69OqJCA4EASUlJEa070VRbZFRbZFRbZNxc27Jly7Zaa0svuMFae9EJuAP4f+HLZcBvw5ebzrtf43DbKikpsZEqLy+PeN2Jptoio9oio9oi4+bagC12kEz1jeDkcAPwfmPM7UA8kGKM+Rlw2hiTa609aYzJBWpHfr4REZGxGnYM3Fr7uLU231pbANwDvGytvR94DlgZvttK4NkJq1LETZqroeUkjGB4UmQsRtIDH8oTwFpjzINAFfDh8SnpbeZMJcQmQVL2+G+7sxXqD0LuIvDoK/0DtJ4G/5RL0y7tZ+DYq3CkHCoroPGoszwuFabMc6bsy8KX50NKHhgz8XXJ296oAtxaWwFUhC83AO8a/5IGUfUGWXUbobMU4sb5Q4hTu+DAi1BwA8xYMvYDK9gNVa/DwRedqeEweOPg2r+EG/8OEtLGtn1rne2/+V+w59fQ3Q65V8EtX4eim0a+jcoKePWf4WwjzH4XzLkVpl8L3pix1RdNjcdg1y+cqW4f5F8Dd3wPphaP7+P0dDqvQWUFVJbDie2AdU7UBTc6r7XxQt1+qDsAB37nvF69YpNh7nJYdB8UlunkKxEbSw/80tn6NAv2/Bz2fxcKl8Lc98C82yA1P7LtdZ+FPb+BLT+B6k3nlucUw+JPQvGHITZxxJvzdbfCzv+Bg7+Dw3+EjmbwxjoH8+KH4MSb8Nq/OQfx0r+Ha/4CfLGjq7n1FGz/Obz5MzhzxAmB4g874fSnf4Wfvh9m3wK3fBVyrhh8G73BXfEEvPW60xPMKIKNTznbiEuF2Tc7YT77Fkia0q/NOqCpygnJ3qn5LfDFOyel+LTz5qmQkA6Jmc40USeGQK1zItv1P1C92Vk2/Tq48Quw9Wn495vguk9B2eNjO/m3n4FDf4D9z8ORl6Er4IR0/jVQ9hgUlUFeydDPs63eCfO6/XByB+x9Fnb/AlLyYeG9zpRROPi61jrvtI6/BlWvc1XVbuhY6jxeXgmkF1yaHr21zr4dlwwe78Q/Xn9t9XB4HfgzYdrVkJgx8nV7uqBuH1l1r8HeFqd24w3PPeeuh7qdDk37GTjbBGfPONd7l8X6IWsuZM2BzNnO5ZRpUX03NaKvEY6X0tJSu2XLltGvGOxm+3M/YGHiKTjwgjMsAU54zb3NCfPchcP3ZOoPw9b/hO3POC9K5hwo/QRccSccegk2/RBO73ZC6OoHnKBNLxi4jVDI6VXXbIGarVC9BXtyJ4aQ85Z97nLnBFNU5uzovU7uhJe+5PTY0gvgXV+GKz4w9ItvrROQNVthx2qnPhuEmTfAovvh8hXODgVOuG76Ibz6T9DRAgvvg2X/AKl5VFRUUHbTTRcG942fh0UPgC/OWaeywgmoQy9B4BRgYNpCJ6Abj0HryYH1+RKcE2iwCzqanG1wkX0pPhUSs8CfFZ5ncry+nZmXlTjtljTFmfunQEIGeH3n2qGz1TmY2s+E543QVuvUevQVsCHIWQDFH4IFH4S0Gc667Wdg3VedIE/Jg9u+A/PfO6IDrqKigrKrCmD/C84+d/w1p/2Tcpz9be57nNciPmXYbQ2quwMOPA9vPuOcELDOCX/hfTD/dmdfrXoNjm+Eqo3O8wbwZ9PiSSXl7FvQ0+EsS8g4F+Z5JTB1ASRNjbxn39EMDUec/XzAdCR84vKEX7Occ1OyM9977BSXX1HstLHxDJwwzkk95/KBx8ZQArWw739h72/g2Abnde6VUXTec74SYuL7wpoTbzrvjE5uh9N7nP10tGKTw52QdCcTOpqddugKnLtPjB8yZzmhnpDuHC/eWGfuiwvPw9eLypzAH0RFRQVlZWVDlmKMGfRrhO4IcPo9QWuh/pBzUB18Ed56w3lhjXdAOPSFhX+Ks7MceAGOrgePDy57nxPcBTcOPJitdQ7UTT90dhwbcg7UK+50XrjqLXBim/NCgvMC5y3iWGgqBbf8pdMzGO6gOfxH+MOXoHYP5JXCrd9wel61+8LTXmdedwC6Wp11kqY6PbRF9zs7y1DazzjDIpt+6LTHkk+zsymRK5v/6ITA+cE9mFAITu10wvHIOufASy9wprSZ5y4nZQ9su1AQOlucnktHsxPqZxuhvQHaGqC93ulFtTeEl9UTaqvDY4ODFGGcHpbxOtsIdQ9ea3oBLPiQE9zZlw3dLlVvwG8/57T53Nvg9u+cC/n+bdev/QP71pHUdsy5bcp8mHe7E/4jeY1Hq7kadvy3E+a94+e9MopgxvUw4zqYeT1kFFHxyiuU3XiDU2vN1vC0zam/9yTqjYXU6c7z7JtmQtp0Z79uPeUEZOCU83lBIDy1nnRenz7GWTdzthNSqfnO6xs4PXC9QK1zghup9ELnRJNT7HTEpi5w6g3Uwr7nnHcox//k1Jo5xzkG593unMz7P+fWE872PD5nf2iqOhfWcamQe6XTEcldyObjrVxTeg2EepxaQ6HwPOjMPT7nZJiY4QT2YO+SrXXarv4gNBxysqj+kJMPna3OY/d0OI9xvvt/CbPfPWhzvHMC/HxtDXD4JadB2+r6hUX4cmc4bFNnQMlKJ7ySc4Z/wOYap7e+9WlnW8br9BzySpzgzS913kJ5vMM2/gVCQeeAffmb53bAXolZThhlX35unldyrkc6Eo3H4eWvO8MKAMnTnOC++qNDB3cUVJSXU3bdQgjUhV+vflOg1jl4EzPOHVTnzxMzR/72NdgNb/wAyv+vc/3av3R6a70nzMCpc/eNS6UxYTrpi+9xQuNiJ83xZK1zoq2scF77GUsgeeoFdxtyf+tsdXqd9QecIOs/tdUN/pgeH/izwz3oqc6JOaPQCezMOU4oxsQPX3soBGfPsKniRRZfUxruLVtn3n8K1MKp3XB6l/P5U++7aXACtzP8Ti5rnhPal9/ptMVQr3PLCSfIT2xzOj0ZRX2BTXrhgJPtqI/TsQgFnc9KejrOhbo/e8ih2UgD3B1j4Bfjz4Sr7hn69p4upxfnzxrduF1qHtz8f2DpI84BnjXn3JDFWHm8Tm/6iruc4RwbCn9L4bKB486RSp8JH/wRXP8we159jivu+vtJFdx9TPgtdUI6TJk7sY/ljYHrH3YC4cXHYMP3nGGgKfNg1s0DT5op09jxyiuUXV82sTWdzxinlz3z+sjWj0uGwhud6XxdbU5Pv6nKeVeVlOOcHBIyxucdhccD/iza/fmQPf/i951327nLnQHnJHpqpzPUkZQTDu1httErZZozXXZHxKVPCI/XCetRfJYWCfcH+HB8sSPrcQ+5fpxzRp8IsYnOh6YTJfcq6rIbJ2d4R0vadLjnGWc4JyH90n8YFy2x/nNfaZxM4pJg+mJnklF7+we4yGD8WdGuQGTM9AVUERGXUoCLiLiUAlxExKUU4CIiLqUAFxFxKQW4iIhLKcBFRFxKAS4i4lIKcBERl1KAi4i4lAJcRMSlFOAiIi6lABcRcSkFuIiISynARURcSgEuIuJSCnAREZdSgIuIuJQCXETEpRTgIiIupQAXEXEpBbiIiEspwEVEXEoBLiLiUr7h7mCMiQfWA3Hh+//CWvtlY0wGsAYoAI4Bd1trGyeuVBFxq+7ubqqrq+no6IhaDampqezbty9qj38xvbXFx8eTn59PTEzMiNYbNsCBTuBma23AGBMDbDDG/A64C1hnrX3CGPMY8BjwaKRPQETevqqrq0lOTqagoABjTFRqaG1tJTk5OSqPPZzW1laSkpJoaGigurqawsLCEa037BCKdQTCV2PCkwVWAKvCy1cBd466ahF5R+jo6CAzMzNq4e0GxhgyMzNH9S7FWGtHsmEvsBWYDTxlrX3UGNNkrU3rd59Ga236IOs+BDwEkJOTU7J69eoRF9dfIBAgKSkponUnmmqLjGqLjBtrS01NZfbs2VGo6JxgMIjX641qDUPpX9vhw4dpbm4ecPuyZcu2WmtLL1jRWjviCUgDyoEFQNN5tzUOt35JSYmNVHl5ecTrTjTVFhnVFhk31rZ3795LW8h5/H6/bWlpiWoNF9O/tsHaCthiB8nUUX0LxVrbBFQA7wFOG2NyAcLz2tFsS0RExmbYADfGTDHGpIUvJwDvBvYDzwErw3dbCTw7QTWKiIwLay2PPPIICxYsoLi4mDVr1gBw8uRJli5dysKFC1mwYAGvvvoqwWCQj33sY333/d73vhfl6i80km+h5AKrwuPgHmCttfa3xpiNwFpjzINAFfDhCaxTRN4mvvq/e9h7omVct3n5tBS+/L4rhr3fr371K7Zv386OHTuor6/nmmuuYenSpfz85z9n+fLlfPGLXyQYDNLe3s727dupqalh9+7dADQ1NY1rzeNh2AC31u4EFg2yvAF410QUJSIyETZs2MBHPvIRvF4vOTk53HTTTWzevJlrrrmGT3ziE3R3d3PnnXeycOFCioqKqKys5OGHH+a9730vt956a7TLv8BIeuAiIuNmJD3liWKH+Nbd0qVLWb9+Pc8//zwPPPAAjzzyCB/96EfZsWMHv//973nqqadYu3YtP/nJTy5xxRenP6UXkXeMpUuXsmbNGoLBIHV1daxfv57Fixdz/PhxsrOz+eQnP8mDDz7Itm3bqK+vJxQK8cEPfpCvf/3rbNu2LdrlX0A9cBF5x/jABz7Axo0bueqqqzDG8J3vfIepU6eyatUqnnzySWJiYkhKSuKnP/0pNTU1fPzjHycUCgHwrW99K8rVX0gBLiJve4FAgNbWVowxPPnkkzz55JMDbl+5ciUrV668YL3J2OvuT0MoIiIupQAXEXEpBbiIiEspwEVEXEoBLiLiUgpwERGXUoCLiLiUAlxE5DwX+8GMY8eOsWDBgktYzdAU4CIiLqW/xBSRS+t3j8GpXeO7zanFcNsTQ9786KOPkpOTw+c//3kAvvKVr2CMYf369TQ2NtLd3c03vvENVqxYMaqH7ejo4FOf+hRbtmzB5/Px3e9+l2XLlrFnzx4+/vGP09XVRSgU4pe//CXTpk3j7rvvprq6mmAwyD/+4z/y53/+52N62gpwEXnbu+eee3j44Yf7Anzt2rW8+OKLfO5znyMlJYX6+nquu+463v/+94/qh5efeuopAHbt2sX+/fu59dZbOXjwID/4wQ/4zGc+w3333UdXVxfBYJAXXniBadOm8fzzzwNc8LuXkVCAi8ildZGe8kRZtGgRdXV1nDhxgrq6OtLT08nNzeVzn/sc69evx+PxUFNTw+nTp5k6deqIt7thwwYefvhhAObPn8/MmTM5ePAgS5Ys4Zvf/CbV1dXcddddzJkzh+LiYr7whS/w6KOPcscdd3DjjTeO+XlpDFxE3hFWrFjBL37xC9asWcM999zDM888Q11dHVu3bmX79u3k5OTQ0dExqm0O9f/F7733Xp577jkSEhJYvnw5L7/8MnPnzmXr1q0UFxfz+OOP87WvfW3Mz0k9cBF5R/jQhz7EZz/7Werr63nllVdYu3Yt2dnZxMTEUF5ezvHjx0e9zaVLl/LMM89w8803c/DgQaqqqpg3bx6VlZUUFRXxt3/7t1RWVrJz507mz59PRkYG999/P0lJSTz99NNjfk4KcBF5R7jssstobW0lLy+P3Nxc7rvvPt73vvdRWlrKwoULmT9//qi3+elPf5q/+qu/ori4GJ/Px9NPP01cXBxr1qzhZz/7GTExMUydOpUvfelLbN68mUceeQSPx0NMTAzf//73x/ycFOAi8o6xa9e5b79kZWWxcePGQe8XCASG3EZBQUHfDx3Hx8cP2pN+/PHHefzxxwcsW758OcuXL4+g6qFpDFxExKXUAxcRGcSuXbt44IEHBiyLi4vjjTfeiFJFF1KAi4gMori4mO3bt0e7jIvSEIqIiEspwEVEXEoBLiLiUgpwEXnbu9i/h3UzBbiIvCMFg8FolzBmCnAReceoqKhg2bJl3HvvvRQXF0e7nDHT1whF5JL69qZvs//M/nHd5vyM+Ty6+NER3XfTpk3s3r2bwsLCca0hGtQDF5F3lMWLF78twhtG0AM3xkwHfgpMBULAD621/2qMyQDWAAXAMeBua23jxJUqIm8HI+0pTxS/3x/Vxx9PI+mB9wB/Z629DLgO+GtjzOXAY8A6a+0cYF34uoiIXCLDBri19qS1dlv4ciuwD8gDVgCrwndbBdw5QTWKiMggzFC/KDHonY0pANYDC4Aqa21av9sarbXpg6zzEPAQQE5OTsnq1asjKjQQCEza73Kqtsiotsi4sbbU1FRmz54dhYrOCQaDeL3eqNYwlP61HT58+ILfy1y2bNlWa23pBStaa0c0AUnAVuCu8PWm825vHG4bJSUlNlLl5eURrzvRVFtkVFtk3Fjb3r17L20hg2hpaYl2CUPqX9tgbQVssYNk6oi+hWKMiQF+CTxjrf1VePFpY0xu+PZcoHa0Zx0REYncsAFujDHAj4F91trv9rvpOWBl+PJK4NnxL09ERIYykj/kuQF4ANhljNkeXvYPwBPAWmPMg0AV8OEJqVBE3hastTj9QRmKHcVnkjCCALfWbgCGavV3jerRROQdKT4+noaGBjIzMxXiQ7DW0tDQQHx8/IjX0Z/Si8iEy8/Pp7q6mrq6uqjV0NHRMapwvJR6a4uPjyc/P3/E6ynARWTCxcTERP3P1ysqKli0aFFUaxhKpLXpf6GIiLiUAlxExKUU4CIiLqUAFxFxKQW4iIhLKcBFRFxKAS4i4lIKcBERl1KAi4i4lAJcRMSlFOAiIi6lABcRcSkFuIiISynARURcSgEuIuJSCnAREZdSgIuIuJQCXETEpRTgIiIupQAXEXEpBbiIiEspwEVEXEoBLiLiUgpwERGXUoCLiLiUAlxExKUU4CIiLqUAFxFxKQW4iIhLDRvgxpifGGNqjTG7+y3LMMa8ZIw5FJ6nT2yZIiJyvpH0wJ8G3nPesseAddbaOcC68HUREbmEhg1wa+164Mx5i1cAq8KXVwF3jm9ZIiIyHGOtHf5OxhQAv7XWLghfb7LWpvW7vdFaO+gwijHmIeAhgJycnJLVq1dHVGggECApKSmidSeaaouMaouMaouMm2tbtmzZVmtt6QU3WGuHnYACYHe/603n3d44ku2UlJTYSJWXl0e87kRTbZFRbZFRbZFxc23AFjtIpkb6LZTTxphcgPC8NsLtiIhIhCIN8OeAleHLK4Fnx6ccEREZqZF8jfC/gY3APGNMtTHmQeAJ4BZjzCHglvB1ERG5hHzD3cFa+5EhbnrXONciIiKjoL/EFBFxKQW4iIhLKcBFRFxKAS4i4lIKcBERl1KAi4i4lAJcRMSlFOAiIi6lABcRcSkFuIiISynARURcSgEuIuJSCnAREZdSgIuIuJQCXETEpRTgIiIupQAXEXEpBbiIiEspwEVEXEoBLiLiUgpwERGXUoCLiLiUAlxExKUU4CIiLqUAFxFxKQW4iIhLKcBFRFxKAS4i4lIKcBERl1KAi4i4lAJcRMSlxhTgxpj3GGMOGGMOG2MeG6+iRERkeBEHuDHGCzwF3AZcDnzEGHP5eBUmIiIXZ6y1ka1ozBLgK9ba5eHrjwNYa7811DqlpaV2y5Yto36sb2/6Nq9Xvk5aWlpEtU60pqYm1RYB1RYZ1RaZaNc2P2M+jy5+dNDbKioqKCsrG3JdY8xWa23p+ct9Y6gnD3ir3/Vq4NpBHvgh4CGAnJwcKioqRv1A1WeqCQaDNDU1RVToRFNtkVFtkVFtkYl2bdXt1VS0Vwx6WyAQiCgbsdZGNAEfBn7U7/oDwL9dbJ2SkhIbqfLy8ojXnWiqLTKqLTKqLTJurg3YYgfJ1LF8iFkNTO93PR84MYbtiYjIKIwlwDcDc4wxhcaYWOAe4LnxKUtERIYT8Ri4tbbHGPM3wO8BL/ATa+2ecatMREQuaiwfYmKtfQF4YZxqERGRUdBfYoqIuJQCXETEpRTgIiIupQAXEXGpiP+UPqIHM6YOOB7h6llA/TiWM55UW2RUW2RUW2TcXNtMa+2U8xde0gAfC2PMFjvI/wKYDFRbZFRbZFRbZN6OtWkIRUTEpRTgIiIu5aYA/2G0C7gI1RYZ1RYZ1RaZt11trhkDFxGRgdzUAxcRkX4U4CIiLuWKAJ/MP55sjDlmjNlljNlujBn978WNby0/McbUGmN291uWYYx5yRhzKDxPn0S1fcUYUxNuu+3GmNujVNt0Y0y5MWafMWaPMeYz4eVRb7uL1Bb1tjPGxBtjNhljdoRr+2p4+WRot6Fqi3q7hevwGmPeNMb8Nnw9ojab9GPg4R9PPgjcgvMjEpuBj1hr90a1sDBjzDGg1Fob9T8QMMYsBQLAT621C8LLvgOcsdY+ET75pVtrB/9hvktf21eAgLX2ny51PefVlgvkWmu3GWOSga3AncDHiHLbXaS2u4ly2xljDOC31gaMMTHABuAzwF1Ev92Gqu09TI597vNAKZBirb0j0uPUDT3wxcBha22ltbYLWA2siHJNk5K1dj1w5rzFK4BV4curcA7+S26I2iYFa+1Ja+228OVWYB/Ob75Gve0uUlvUhX/tKxC+GhOeLJOj3YaqLeqMMfnAe4Ef9VscUZu5IcAH+/HkSbEDh1ngD8aYreEfcJ5scqy1J8EJAyA7yvWc72+MMTvDQyxRGd7pzxhTACwC3mCStd15tcEkaLvwUMB2oBZ4yVo7adptiNog+u32L8DfA6F+yyJqMzcEuBlk2aQ4k4bdYK29GrgN+OvwUIGMzPeBWcBC4CTwz9EsxhiTBPwS+Ky1tiWatZxvkNomRdtZa4PW2oU4v4m72BizIBp1DGaI2qLabsaYO4Baa+3W8dieGwJ8Uv94srX2RHheC/waZ8hnMjkdHkftHU+tjXI9fay1p8MHWQj4D6LYduFx0l8Cz1hrfxVePCnabrDaJlPbhetpAipwxpgnRbv16l/bJGi3G4D3hz87Ww3cbIz5GRG2mRsCfNL+eLIxxh/+YAljjB+4Fdh98bUuueeAleHLK4Fno1jLAL07bNgHiFLbhT/w+jGwz1r73X43Rb3thqptMrSdMWaKMSYtfDkBeDewn8nRboPWFu12s9Y+bq3Nt9YW4GTZy9ba+4m0zay1k34Cbsf5JsoR4IvRrqdfXUXAjvC0J9q1Af+N87awG+edy4NAJrAOOBSeZ0yi2v4L2AXsDO/AuVGq7c9whuV2AtvD0+2Toe0uUlvU2w64EngzXMNu4Evh5ZOh3YaqLert1q/GMuC3Y2mzSf81QhERGZwbhlBERGQQCnAREZdSgIuIuJQCXETEpRTgIiIupQAXEXEpBbiIiEv9f8awBMLO7Rc9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在被保存的模型是  NuclearFuelBurnupCal_CNN_ASS_5_fold_2021-01-18.h5\n",
      "模型已经被保存。\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_stamp = time.time()\n",
    "time_local = time.localtime(time_stamp)\n",
    "dt = time.strftime(\"%Y-%m-%d\", time_local)\n",
    "print(dt)\n",
    "\n",
    "K = 5\n",
    "seed = 2020\n",
    "\n",
    "ass_prediction = np.zeros((len(y_test),1))\n",
    "pin_prediction = np.zeros((len(y_test),1))\n",
    "ass_val_prediction = np.zeros((len(y_pre_train),1))\n",
    "pin_val_prediction = np.zeros((len(y_pre_train),1))\n",
    "\n",
    "skf = KFold(n_splits=K, shuffle=True, random_state=seed)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_pre_train,y_pre_train)):\n",
    "        print(\"fold {}\".format(i+1))\n",
    "        X_tr, X_val = X_pre_train[train_index], X_pre_train[val_index]\n",
    "        y_tr, y_val = y_pre_train[train_index], y_pre_train[val_index]\n",
    "        \n",
    "        history1 = m.fit(X_tr,  y_tr[:,0], epochs=300, batch_size=64, callbacks=[learning_rate, early_stopping] ,\n",
    "                     validation_data = (X_val, y_val[:,0]))\n",
    "        \n",
    "        m.summary()\n",
    "        \n",
    "        plot_learning_curves(history1)\n",
    "        \n",
    "        ass_prediction += m.predict(X_test) / skf.n_splits\n",
    "        ass_val_prediction += m.predict(X_pre_train) / skf.n_splits\n",
    "\n",
    "        model_name = 'NuclearFuelBurnupCal_CNN_' + 'ASS' + '_'+ str(i+1)+ '_fold_'+dt + '.h5'\n",
    "        print('正在被保存的模型是 ', model_name)\n",
    "        m.save(model_name)\n",
    "        print('模型已经被保存。')\n",
    "        \n",
    "        \n",
    "        history2 = m2.fit(X_tr,  y_tr[:,1], epochs=300, batch_size=64, callbacks=[learning_rate, early_stopping] ,\n",
    "                     validation_data = (X_val, y_val[:,1]))\n",
    "        \n",
    "        m2.summary()\n",
    "        \n",
    "        plot_learning_curves(history2)\n",
    "        \n",
    "        pin_prediction += m2.predict(X_test) / skf.n_splits\n",
    "        pin_val_prediction += m2.predict(X_pre_train) / skf.n_splits\n",
    "\n",
    "        model_name2 = 'NuclearFuelBurnupCal_CNN_' + 'Pin' + '_'+ str(i+1)+ '_fold_'+dt + '.h5'\n",
    "        print('正在被保存的模型是 ', model_name2)\n",
    "        m2.save(model_name2)\n",
    "        print('模型已经被保存。')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAssBurnupCal</th>\n",
       "      <th>MaxPinBurnupCal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>57732</td>\n",
       "      <td>63664.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>49679</td>\n",
       "      <td>53156.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108820</th>\n",
       "      <td>54567</td>\n",
       "      <td>60857.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21146</th>\n",
       "      <td>56139</td>\n",
       "      <td>63804.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116533</th>\n",
       "      <td>62291</td>\n",
       "      <td>66056.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86734</th>\n",
       "      <td>59847</td>\n",
       "      <td>63212.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>57746</td>\n",
       "      <td>63966.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>57982</td>\n",
       "      <td>63355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46670</th>\n",
       "      <td>57080</td>\n",
       "      <td>63106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12642</th>\n",
       "      <td>56720</td>\n",
       "      <td>62843.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MaxAssBurnupCal  MaxPinBurnupCal\n",
       "47057             57732          63664.2\n",
       "24481             49679          53156.4\n",
       "108820            54567          60857.7\n",
       "21146             56139          63804.1\n",
       "116533            62291          66056.1\n",
       "...                 ...              ...\n",
       "86734             59847          63212.1\n",
       "9793              57746          63966.7\n",
       "11389             57982          63355.0\n",
       "46670             57080          63106.4\n",
       "12642             56720          62843.1\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pre_train1, X_test1, y_pre_train1, y_test1 = train_test_split(pre_data.iloc[:,:-2], pre_data.iloc[:,-2:], \n",
    "                                                           random_state=seed, train_size=0.9, \n",
    "                                                           test_size=0.1)\n",
    "y_train_pred  = y_pre_train1.copy()\n",
    "y_test_pred  = y_test1.copy()\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple\n",
      "Collecting keras\n",
      "  Downloading http://pypi.doubanio.com/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/alexhang/anaconda3/envs/tf_gpu/lib/python3.7/site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: h5py in /home/alexhang/anaconda3/envs/tf_gpu/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/alexhang/anaconda3/envs/tf_gpu/lib/python3.7/site-packages (from keras) (1.19.2)\n",
      "Requirement already satisfied: six in /home/alexhang/anaconda3/envs/tf_gpu/lib/python3.7/site-packages (from h5py->keras) (1.15.0)\n",
      "Collecting pyyaml\n",
      "  Downloading http://pypi.doubanio.com/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=44620 sha256=6afe041bddab3249cb68bfc2a2433aaca2aa6465e618ff511ee6fc5bf2aab9d8\n",
      "  Stored in directory: /home/alexhang/.cache/pip/wheels/5e/82/f1/7e4248e673e7d48c3c4acf291b6701923fedc7956653f14cbb\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.4.3 pyyaml-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras\n",
    "\n",
    "ass_model1 = load_model('NuclearFuelBurnupCal_CNN_ASS_3_fold_2021-01-18.h5')\n",
    "y_train_pred['MaxAssBurnupCal'] = ass_model1.predict(X_pre_train, batch_size=32)\n",
    "y_test_pred['MaxAssBurnupCal'] = ass_model1.predict(X_test, batch_size=32)\n",
    "\n",
    "pin_model1 = load_model('NuclearFuelBurnupCal_CNN_Pin_3_fold_2021-01-18.h5')\n",
    "y_train_pred['MaxPinBurnupCal'] = pin_model1.predict(X_pre_train, batch_size=32)\n",
    "y_test_pred['MaxPinBurnupCal'] = pin_model1.predict(X_test, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred.to_csv('fuel_test07_train_pred_fold3_20210119.csv')\n",
    "y_test_pred.to_csv('fuel_test07_test_pred_fold3_20210119.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalError(pred, test):\n",
    "    \n",
    "    col_name = []\n",
    "    for col in pred.columns:\n",
    "        col_name.append(col+'_pred')\n",
    "    for col in test.columns:\n",
    "        col_name.append(col+'_test')  \n",
    "    \n",
    "    pred.index = test.index\n",
    "    pred_error = pd.concat([pred,test], axis=1)\n",
    "    print(pred_error)\n",
    "    pred_error.columns = col_name\n",
    "    \n",
    "    error_col = []\n",
    "    for col in pred.columns:\n",
    "        pred_error[col + '_error'] = np.array(pred[col]) - np.array(test[col])\n",
    "        error_col.append(col + '_error')\n",
    "    bin_range = np.linspace(0,1000,11).tolist() + [2000, 3000, 4000, 5000, 10000]\n",
    "    bin_label = np.linspace(1,15,15).tolist()\n",
    "    \n",
    "    range_col = []\n",
    "    for col in error_col:\n",
    "        pred_error[col+'_range'] = pd.cut(\n",
    "                                        abs(np.array(pred_error[col])),\n",
    "                                        bins=bin_range\n",
    "                                        )\n",
    "        range_col.append(col+'_range')\n",
    "        pred_error[col+'_label'] = pd.cut(\n",
    "                                        abs(np.array(pred_error[col])),\n",
    "                                        bins=bin_range,\n",
    "                                        labels=bin_label\n",
    "                                        )\n",
    "        range_col.append(col+'_label')\n",
    "        \n",
    "    for col in [c for c in range_col if '_label' not in c]:\n",
    "        print('{}特征误差范围及统计个数'.format(col))\n",
    "        print(pred_error[col].value_counts())\n",
    "        \n",
    "    return pred_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MaxAssBurnupCal  MaxPinBurnupCal  MaxAssBurnupCal  MaxPinBurnupCal\n",
      "47057      57724.203125     63672.667969            57732          63664.2\n",
      "24481      49722.644531     52982.464844            49679          53156.4\n",
      "108820     54521.828125     60906.117188            54567          60857.7\n",
      "21146      56165.160156     63820.390625            56139          63804.1\n",
      "116533     62282.859375     65916.351562            62291          66056.1\n",
      "...                 ...              ...              ...              ...\n",
      "86734      59819.296875     63121.546875            59847          63212.1\n",
      "9793       57790.648438     63941.816406            57746          63966.7\n",
      "11389      57999.683594     63325.570312            57982          63355.0\n",
      "46670      57073.835938     62924.906250            57080          63106.4\n",
      "12642      56677.523438     62745.207031            56720          62843.1\n",
      "\n",
      "[12000 rows x 4 columns]\n",
      "MaxAssBurnupCal_error_range特征误差范围及统计个数\n",
      "(0.0, 100.0]         10871\n",
      "(100.0, 200.0]         983\n",
      "(200.0, 300.0]         107\n",
      "(300.0, 400.0]          18\n",
      "(400.0, 500.0]          10\n",
      "(500.0, 600.0]           5\n",
      "(700.0, 800.0]           2\n",
      "(600.0, 700.0]           1\n",
      "(800.0, 900.0]           1\n",
      "(1000.0, 2000.0]         1\n",
      "(4000.0, 5000.0]         1\n",
      "(900.0, 1000.0]          0\n",
      "(2000.0, 3000.0]         0\n",
      "(3000.0, 4000.0]         0\n",
      "(5000.0, 10000.0]        0\n",
      "Name: MaxAssBurnupCal_error_range, dtype: int64\n",
      "MaxPinBurnupCal_error_range特征误差范围及统计个数\n",
      "(0.0, 100.0]         7625\n",
      "(100.0, 200.0]       2880\n",
      "(200.0, 300.0]        915\n",
      "(300.0, 400.0]        292\n",
      "(400.0, 500.0]        118\n",
      "(500.0, 600.0]         67\n",
      "(600.0, 700.0]         41\n",
      "(1000.0, 2000.0]       25\n",
      "(700.0, 800.0]         20\n",
      "(800.0, 900.0]         11\n",
      "(900.0, 1000.0]         6\n",
      "(2000.0, 3000.0]        0\n",
      "(3000.0, 4000.0]        0\n",
      "(4000.0, 5000.0]        0\n",
      "(5000.0, 10000.0]       0\n",
      "Name: MaxPinBurnupCal_error_range, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAssBurnupCal_pred</th>\n",
       "      <th>MaxPinBurnupCal_pred</th>\n",
       "      <th>MaxAssBurnupCal_test</th>\n",
       "      <th>MaxPinBurnupCal_test</th>\n",
       "      <th>MaxAssBurnupCal_error</th>\n",
       "      <th>MaxPinBurnupCal_error</th>\n",
       "      <th>MaxAssBurnupCal_error_range</th>\n",
       "      <th>MaxAssBurnupCal_error_label</th>\n",
       "      <th>MaxPinBurnupCal_error_range</th>\n",
       "      <th>MaxPinBurnupCal_error_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>57724.203125</td>\n",
       "      <td>63672.667969</td>\n",
       "      <td>57732</td>\n",
       "      <td>63664.2</td>\n",
       "      <td>-7.796875</td>\n",
       "      <td>8.467969</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>49722.644531</td>\n",
       "      <td>52982.464844</td>\n",
       "      <td>49679</td>\n",
       "      <td>53156.4</td>\n",
       "      <td>43.644531</td>\n",
       "      <td>-173.935156</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(100.0, 200.0]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108820</th>\n",
       "      <td>54521.828125</td>\n",
       "      <td>60906.117188</td>\n",
       "      <td>54567</td>\n",
       "      <td>60857.7</td>\n",
       "      <td>-45.171875</td>\n",
       "      <td>48.417188</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21146</th>\n",
       "      <td>56165.160156</td>\n",
       "      <td>63820.390625</td>\n",
       "      <td>56139</td>\n",
       "      <td>63804.1</td>\n",
       "      <td>26.160156</td>\n",
       "      <td>16.290625</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116533</th>\n",
       "      <td>62282.859375</td>\n",
       "      <td>65916.351562</td>\n",
       "      <td>62291</td>\n",
       "      <td>66056.1</td>\n",
       "      <td>-8.140625</td>\n",
       "      <td>-139.748438</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(100.0, 200.0]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86734</th>\n",
       "      <td>59819.296875</td>\n",
       "      <td>63121.546875</td>\n",
       "      <td>59847</td>\n",
       "      <td>63212.1</td>\n",
       "      <td>-27.703125</td>\n",
       "      <td>-90.553125</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>57790.648438</td>\n",
       "      <td>63941.816406</td>\n",
       "      <td>57746</td>\n",
       "      <td>63966.7</td>\n",
       "      <td>44.648438</td>\n",
       "      <td>-24.883594</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>57999.683594</td>\n",
       "      <td>63325.570312</td>\n",
       "      <td>57982</td>\n",
       "      <td>63355.0</td>\n",
       "      <td>17.683594</td>\n",
       "      <td>-29.429688</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46670</th>\n",
       "      <td>57073.835938</td>\n",
       "      <td>62924.906250</td>\n",
       "      <td>57080</td>\n",
       "      <td>63106.4</td>\n",
       "      <td>-6.164062</td>\n",
       "      <td>-181.493750</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(100.0, 200.0]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12642</th>\n",
       "      <td>56677.523438</td>\n",
       "      <td>62745.207031</td>\n",
       "      <td>56720</td>\n",
       "      <td>62843.1</td>\n",
       "      <td>-42.476562</td>\n",
       "      <td>-97.892969</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MaxAssBurnupCal_pred  MaxPinBurnupCal_pred  MaxAssBurnupCal_test  \\\n",
       "47057           57724.203125          63672.667969                 57732   \n",
       "24481           49722.644531          52982.464844                 49679   \n",
       "108820          54521.828125          60906.117188                 54567   \n",
       "21146           56165.160156          63820.390625                 56139   \n",
       "116533          62282.859375          65916.351562                 62291   \n",
       "...                      ...                   ...                   ...   \n",
       "86734           59819.296875          63121.546875                 59847   \n",
       "9793            57790.648438          63941.816406                 57746   \n",
       "11389           57999.683594          63325.570312                 57982   \n",
       "46670           57073.835938          62924.906250                 57080   \n",
       "12642           56677.523438          62745.207031                 56720   \n",
       "\n",
       "        MaxPinBurnupCal_test  MaxAssBurnupCal_error  MaxPinBurnupCal_error  \\\n",
       "47057                63664.2              -7.796875               8.467969   \n",
       "24481                53156.4              43.644531            -173.935156   \n",
       "108820               60857.7             -45.171875              48.417188   \n",
       "21146                63804.1              26.160156              16.290625   \n",
       "116533               66056.1              -8.140625            -139.748438   \n",
       "...                      ...                    ...                    ...   \n",
       "86734                63212.1             -27.703125             -90.553125   \n",
       "9793                 63966.7              44.648438             -24.883594   \n",
       "11389                63355.0              17.683594             -29.429688   \n",
       "46670                63106.4              -6.164062            -181.493750   \n",
       "12642                62843.1             -42.476562             -97.892969   \n",
       "\n",
       "       MaxAssBurnupCal_error_range MaxAssBurnupCal_error_label  \\\n",
       "47057                 (0.0, 100.0]                         1.0   \n",
       "24481                 (0.0, 100.0]                         1.0   \n",
       "108820                (0.0, 100.0]                         1.0   \n",
       "21146                 (0.0, 100.0]                         1.0   \n",
       "116533                (0.0, 100.0]                         1.0   \n",
       "...                            ...                         ...   \n",
       "86734                 (0.0, 100.0]                         1.0   \n",
       "9793                  (0.0, 100.0]                         1.0   \n",
       "11389                 (0.0, 100.0]                         1.0   \n",
       "46670                 (0.0, 100.0]                         1.0   \n",
       "12642                 (0.0, 100.0]                         1.0   \n",
       "\n",
       "       MaxPinBurnupCal_error_range MaxPinBurnupCal_error_label  \n",
       "47057                 (0.0, 100.0]                         1.0  \n",
       "24481               (100.0, 200.0]                         2.0  \n",
       "108820                (0.0, 100.0]                         1.0  \n",
       "21146                 (0.0, 100.0]                         1.0  \n",
       "116533              (100.0, 200.0]                         2.0  \n",
       "...                            ...                         ...  \n",
       "86734                 (0.0, 100.0]                         1.0  \n",
       "9793                  (0.0, 100.0]                         1.0  \n",
       "11389                 (0.0, 100.0]                         1.0  \n",
       "46670               (100.0, 200.0]                         2.0  \n",
       "12642                 (0.0, 100.0]                         1.0  \n",
       "\n",
       "[12000 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_pred_error = CalError(y_test_pred, y_test1)\n",
    "CNN_pred_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MaxAssBurnupCal  MaxPinBurnupCal  MaxAssBurnupCal  MaxPinBurnupCal\n",
      "47057      57722.531250     63675.281250            57732          63664.2\n",
      "24481      49718.437500     52978.894531            49679          53156.4\n",
      "108820     54519.496094     60908.343750            54567          60857.7\n",
      "21146      56164.222656     63822.800781            56139          63804.1\n",
      "116533     62282.531250     65920.429688            62291          66056.1\n",
      "...                 ...              ...              ...              ...\n",
      "86734      59816.746094     63125.093750            59847          63212.1\n",
      "9793       57788.964844     63944.562500            57746          63966.7\n",
      "11389      57999.347656     63329.812500            57982          63355.0\n",
      "46670      57072.511719     62927.730469            57080          63106.4\n",
      "12642      56676.312500     62747.386719            56720          62843.1\n",
      "\n",
      "[12000 rows x 4 columns]\n",
      "MaxAssBurnupCal_error_range特征误差范围及统计个数\n",
      "(0.0, 100.0]         10856\n",
      "(100.0, 200.0]         997\n",
      "(200.0, 300.0]         105\n",
      "(300.0, 400.0]          19\n",
      "(400.0, 500.0]          10\n",
      "(500.0, 600.0]           5\n",
      "(700.0, 800.0]           2\n",
      "(600.0, 700.0]           1\n",
      "(800.0, 900.0]           1\n",
      "(1000.0, 2000.0]         1\n",
      "(4000.0, 5000.0]         1\n",
      "(900.0, 1000.0]          0\n",
      "(2000.0, 3000.0]         0\n",
      "(3000.0, 4000.0]         0\n",
      "(5000.0, 10000.0]        0\n",
      "Name: MaxAssBurnupCal_error_range, dtype: int64\n",
      "MaxPinBurnupCal_error_range特征误差范围及统计个数\n",
      "(0.0, 100.0]         7637\n",
      "(100.0, 200.0]       2885\n",
      "(200.0, 300.0]        905\n",
      "(300.0, 400.0]        287\n",
      "(400.0, 500.0]        118\n",
      "(500.0, 600.0]         66\n",
      "(600.0, 700.0]         41\n",
      "(1000.0, 2000.0]       25\n",
      "(700.0, 800.0]         19\n",
      "(800.0, 900.0]         10\n",
      "(900.0, 1000.0]         7\n",
      "(2000.0, 3000.0]        0\n",
      "(3000.0, 4000.0]        0\n",
      "(4000.0, 5000.0]        0\n",
      "(5000.0, 10000.0]       0\n",
      "Name: MaxPinBurnupCal_error_range, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAssBurnupCal_pred</th>\n",
       "      <th>MaxPinBurnupCal_pred</th>\n",
       "      <th>MaxAssBurnupCal_test</th>\n",
       "      <th>MaxPinBurnupCal_test</th>\n",
       "      <th>MaxAssBurnupCal_error</th>\n",
       "      <th>MaxPinBurnupCal_error</th>\n",
       "      <th>MaxAssBurnupCal_error_range</th>\n",
       "      <th>MaxAssBurnupCal_error_label</th>\n",
       "      <th>MaxPinBurnupCal_error_range</th>\n",
       "      <th>MaxPinBurnupCal_error_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>57722.531250</td>\n",
       "      <td>63675.281250</td>\n",
       "      <td>57732</td>\n",
       "      <td>63664.2</td>\n",
       "      <td>-9.468750</td>\n",
       "      <td>11.081250</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>49718.437500</td>\n",
       "      <td>52978.894531</td>\n",
       "      <td>49679</td>\n",
       "      <td>53156.4</td>\n",
       "      <td>39.437500</td>\n",
       "      <td>-177.505469</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(100.0, 200.0]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108820</th>\n",
       "      <td>54519.496094</td>\n",
       "      <td>60908.343750</td>\n",
       "      <td>54567</td>\n",
       "      <td>60857.7</td>\n",
       "      <td>-47.503906</td>\n",
       "      <td>50.643750</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21146</th>\n",
       "      <td>56164.222656</td>\n",
       "      <td>63822.800781</td>\n",
       "      <td>56139</td>\n",
       "      <td>63804.1</td>\n",
       "      <td>25.222656</td>\n",
       "      <td>18.700781</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116533</th>\n",
       "      <td>62282.531250</td>\n",
       "      <td>65920.429688</td>\n",
       "      <td>62291</td>\n",
       "      <td>66056.1</td>\n",
       "      <td>-8.468750</td>\n",
       "      <td>-135.670313</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(100.0, 200.0]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86734</th>\n",
       "      <td>59816.746094</td>\n",
       "      <td>63125.093750</td>\n",
       "      <td>59847</td>\n",
       "      <td>63212.1</td>\n",
       "      <td>-30.253906</td>\n",
       "      <td>-87.006250</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>57788.964844</td>\n",
       "      <td>63944.562500</td>\n",
       "      <td>57746</td>\n",
       "      <td>63966.7</td>\n",
       "      <td>42.964844</td>\n",
       "      <td>-22.137500</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>57999.347656</td>\n",
       "      <td>63329.812500</td>\n",
       "      <td>57982</td>\n",
       "      <td>63355.0</td>\n",
       "      <td>17.347656</td>\n",
       "      <td>-25.187500</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46670</th>\n",
       "      <td>57072.511719</td>\n",
       "      <td>62927.730469</td>\n",
       "      <td>57080</td>\n",
       "      <td>63106.4</td>\n",
       "      <td>-7.488281</td>\n",
       "      <td>-178.669531</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(100.0, 200.0]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12642</th>\n",
       "      <td>56676.312500</td>\n",
       "      <td>62747.386719</td>\n",
       "      <td>56720</td>\n",
       "      <td>62843.1</td>\n",
       "      <td>-43.687500</td>\n",
       "      <td>-95.713281</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 100.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MaxAssBurnupCal_pred  MaxPinBurnupCal_pred  MaxAssBurnupCal_test  \\\n",
       "47057           57722.531250          63675.281250                 57732   \n",
       "24481           49718.437500          52978.894531                 49679   \n",
       "108820          54519.496094          60908.343750                 54567   \n",
       "21146           56164.222656          63822.800781                 56139   \n",
       "116533          62282.531250          65920.429688                 62291   \n",
       "...                      ...                   ...                   ...   \n",
       "86734           59816.746094          63125.093750                 59847   \n",
       "9793            57788.964844          63944.562500                 57746   \n",
       "11389           57999.347656          63329.812500                 57982   \n",
       "46670           57072.511719          62927.730469                 57080   \n",
       "12642           56676.312500          62747.386719                 56720   \n",
       "\n",
       "        MaxPinBurnupCal_test  MaxAssBurnupCal_error  MaxPinBurnupCal_error  \\\n",
       "47057                63664.2              -9.468750              11.081250   \n",
       "24481                53156.4              39.437500            -177.505469   \n",
       "108820               60857.7             -47.503906              50.643750   \n",
       "21146                63804.1              25.222656              18.700781   \n",
       "116533               66056.1              -8.468750            -135.670313   \n",
       "...                      ...                    ...                    ...   \n",
       "86734                63212.1             -30.253906             -87.006250   \n",
       "9793                 63966.7              42.964844             -22.137500   \n",
       "11389                63355.0              17.347656             -25.187500   \n",
       "46670                63106.4              -7.488281            -178.669531   \n",
       "12642                62843.1             -43.687500             -95.713281   \n",
       "\n",
       "       MaxAssBurnupCal_error_range MaxAssBurnupCal_error_label  \\\n",
       "47057                 (0.0, 100.0]                         1.0   \n",
       "24481                 (0.0, 100.0]                         1.0   \n",
       "108820                (0.0, 100.0]                         1.0   \n",
       "21146                 (0.0, 100.0]                         1.0   \n",
       "116533                (0.0, 100.0]                         1.0   \n",
       "...                            ...                         ...   \n",
       "86734                 (0.0, 100.0]                         1.0   \n",
       "9793                  (0.0, 100.0]                         1.0   \n",
       "11389                 (0.0, 100.0]                         1.0   \n",
       "46670                 (0.0, 100.0]                         1.0   \n",
       "12642                 (0.0, 100.0]                         1.0   \n",
       "\n",
       "       MaxPinBurnupCal_error_range MaxPinBurnupCal_error_label  \n",
       "47057                 (0.0, 100.0]                         1.0  \n",
       "24481               (100.0, 200.0]                         2.0  \n",
       "108820                (0.0, 100.0]                         1.0  \n",
       "21146                 (0.0, 100.0]                         1.0  \n",
       "116533              (100.0, 200.0]                         2.0  \n",
       "...                            ...                         ...  \n",
       "86734                 (0.0, 100.0]                         1.0  \n",
       "9793                  (0.0, 100.0]                         1.0  \n",
       "11389                 (0.0, 100.0]                         1.0  \n",
       "46670               (100.0, 200.0]                         2.0  \n",
       "12642                 (0.0, 100.0]                         1.0  \n",
       "\n",
       "[12000 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_fold_comb = (y_test_pred_fold3 + y_test_pred_fold2 + y_test_pred_fold1)/3\n",
    "CNN_pred_error = CalError(y_test_pred_fold_comb, y_test1)\n",
    "CNN_pred_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAssBurnupCal</th>\n",
       "      <th>MaxPinBurnupCal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>57724.203125</td>\n",
       "      <td>63672.667969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>49722.644531</td>\n",
       "      <td>52982.464844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108820</th>\n",
       "      <td>54521.828125</td>\n",
       "      <td>60906.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21146</th>\n",
       "      <td>56165.160156</td>\n",
       "      <td>63820.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116533</th>\n",
       "      <td>62282.859375</td>\n",
       "      <td>65916.351562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86734</th>\n",
       "      <td>59819.296875</td>\n",
       "      <td>63121.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>57790.648438</td>\n",
       "      <td>63941.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>57999.683594</td>\n",
       "      <td>63325.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46670</th>\n",
       "      <td>57073.835938</td>\n",
       "      <td>62924.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12642</th>\n",
       "      <td>56677.523438</td>\n",
       "      <td>62745.207031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MaxAssBurnupCal  MaxPinBurnupCal\n",
       "47057      57724.203125     63672.667969\n",
       "24481      49722.644531     52982.464844\n",
       "108820     54521.828125     60906.117188\n",
       "21146      56165.160156     63820.390625\n",
       "116533     62282.859375     65916.351562\n",
       "...                 ...              ...\n",
       "86734      59819.296875     63121.546875\n",
       "9793       57790.648438     63941.816406\n",
       "11389      57999.683594     63325.570312\n",
       "46670      57073.835938     62924.906250\n",
       "12642      56677.523438     62745.207031\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_fold3 = y_train_pred.copy()\n",
    "y_test_pred_fold3 = y_test_pred.copy()\n",
    "y_test_pred_fold3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAssBurnupCal</th>\n",
       "      <th>MaxPinBurnupCal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>57720.343750</td>\n",
       "      <td>63678.144531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>49717.042969</td>\n",
       "      <td>52977.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108820</th>\n",
       "      <td>54519.039062</td>\n",
       "      <td>60909.628906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21146</th>\n",
       "      <td>56162.347656</td>\n",
       "      <td>63826.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116533</th>\n",
       "      <td>62278.753906</td>\n",
       "      <td>65926.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86734</th>\n",
       "      <td>59818.566406</td>\n",
       "      <td>63128.066406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>57787.554688</td>\n",
       "      <td>63947.121094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>57998.234375</td>\n",
       "      <td>63333.433594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46670</th>\n",
       "      <td>57070.410156</td>\n",
       "      <td>62931.074219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12642</th>\n",
       "      <td>56675.250000</td>\n",
       "      <td>62751.093750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MaxAssBurnupCal  MaxPinBurnupCal\n",
       "47057      57720.343750     63678.144531\n",
       "24481      49717.042969     52977.589844\n",
       "108820     54519.039062     60909.628906\n",
       "21146      56162.347656     63826.910156\n",
       "116533     62278.753906     65926.046875\n",
       "...                 ...              ...\n",
       "86734      59818.566406     63128.066406\n",
       "9793       57787.554688     63947.121094\n",
       "11389      57998.234375     63333.433594\n",
       "46670      57070.410156     62931.074219\n",
       "12642      56675.250000     62751.093750\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_fold2 = y_train_pred.copy()\n",
    "y_test_pred_fold2 = y_test_pred.copy()\n",
    "y_test_pred_fold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxAssBurnupCal</th>\n",
       "      <th>MaxPinBurnupCal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47057</th>\n",
       "      <td>57723.042969</td>\n",
       "      <td>63675.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>49715.621094</td>\n",
       "      <td>52976.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108820</th>\n",
       "      <td>54517.621094</td>\n",
       "      <td>60909.277344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21146</th>\n",
       "      <td>56165.167969</td>\n",
       "      <td>63821.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116533</th>\n",
       "      <td>62285.980469</td>\n",
       "      <td>65918.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86734</th>\n",
       "      <td>59812.375000</td>\n",
       "      <td>63125.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>57788.687500</td>\n",
       "      <td>63944.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>58000.125000</td>\n",
       "      <td>63330.433594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46670</th>\n",
       "      <td>57073.273438</td>\n",
       "      <td>62927.195312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12642</th>\n",
       "      <td>56676.171875</td>\n",
       "      <td>62745.851562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MaxAssBurnupCal  MaxPinBurnupCal\n",
       "47057      57723.042969     63675.031250\n",
       "24481      49715.621094     52976.640625\n",
       "108820     54517.621094     60909.277344\n",
       "21146      56165.167969     63821.117188\n",
       "116533     62285.980469     65918.875000\n",
       "...                 ...              ...\n",
       "86734      59812.375000     63125.671875\n",
       "9793       57788.687500     63944.750000\n",
       "11389      58000.125000     63330.433594\n",
       "46670      57073.273438     62927.195312\n",
       "12642      56676.171875     62745.851562\n",
       "\n",
       "[12000 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_fold1 = y_train_pred.copy()\n",
    "y_test_pred_fold1 = y_test_pred.copy()\n",
    "y_test_pred_fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN_pred_error.to_csv('nuclear_cnn_pred_error_test03_20210115.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ass_pred_outlier_list = []\n",
    "pin_pred_outlier_list = []\n",
    "threshold_value = 1000\n",
    "\n",
    "for index,row in CNN_pred_error.iterrows():\n",
    "    if abs(CNN_pred_error.loc[index, 'MaxAssBurnupCal_error']) >= threshold_value:\n",
    "        ass_pred_outlier_list.append(index)\n",
    "        print('MaxAss误差大于{}的行号是{}。'.format(threshold_value, index))\n",
    "        \n",
    "    elif abs(CNN_pred_error.loc[index, 'MaxPinBurnupCal_error']) >= threshold_value:\n",
    "        pin_pred_outlier_list.append(index)\n",
    "        print('MaxPin误差大于{}的行号是{}。'.format(threshold_value, index))\n",
    "            \n",
    "ass_pred_outlier = pre_data.loc[ass_pred_outlier_list, :]\n",
    "pin_pred_outlier = pre_data.loc[pin_pred_outlier_list, :]\n",
    "ass_pred_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pin_pred_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pin_pred_outlier_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
