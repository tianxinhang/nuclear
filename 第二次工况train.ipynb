{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexhang/project/data_analysis/PRO/20220315_cz'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "path = os.getcwd()\n",
    "path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_file_1 = \"./data/1-new.xlsx\"\n",
    "all_data_1 = pd.read_excel(all_data_file_1)\n",
    "all_data_file_2 = \"./data/2-new.xlsx\"\n",
    "all_data_2 = pd.read_excel(all_data_file_2)\n",
    "# test_data = pd.read_csv(test_data_file, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>W</th>\n",
       "      <th>P</th>\n",
       "      <th>T0L</th>\n",
       "      <th>T0R</th>\n",
       "      <th>Tx</th>\n",
       "      <th>T1</th>\n",
       "      <th>Y0L</th>\n",
       "      <th>Y0R</th>\n",
       "      <th>Y1</th>\n",
       "      <th>...</th>\n",
       "      <th>TD3.1</th>\n",
       "      <th>TD4.1</th>\n",
       "      <th>TD1</th>\n",
       "      <th>TD2</th>\n",
       "      <th>TD3</th>\n",
       "      <th>TD4</th>\n",
       "      <th>TD5</th>\n",
       "      <th>TD6</th>\n",
       "      <th>TD7</th>\n",
       "      <th>TD8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31680.0000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "      <td>31680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15840.5000</td>\n",
       "      <td>2656.233474</td>\n",
       "      <td>432.091688</td>\n",
       "      <td>561.128188</td>\n",
       "      <td>563.492266</td>\n",
       "      <td>471.670777</td>\n",
       "      <td>248.994842</td>\n",
       "      <td>2.756224</td>\n",
       "      <td>2.935786</td>\n",
       "      <td>2.608339</td>\n",
       "      <td>...</td>\n",
       "      <td>328.961897</td>\n",
       "      <td>453.129261</td>\n",
       "      <td>310.201357</td>\n",
       "      <td>293.069823</td>\n",
       "      <td>306.183258</td>\n",
       "      <td>297.543472</td>\n",
       "      <td>278.528936</td>\n",
       "      <td>271.314905</td>\n",
       "      <td>259.272544</td>\n",
       "      <td>267.263554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9145.3726</td>\n",
       "      <td>927.085374</td>\n",
       "      <td>305.557372</td>\n",
       "      <td>67.758272</td>\n",
       "      <td>65.252626</td>\n",
       "      <td>133.874513</td>\n",
       "      <td>48.088155</td>\n",
       "      <td>1.421472</td>\n",
       "      <td>1.520984</td>\n",
       "      <td>1.762993</td>\n",
       "      <td>...</td>\n",
       "      <td>84.311797</td>\n",
       "      <td>130.885639</td>\n",
       "      <td>75.916886</td>\n",
       "      <td>72.575196</td>\n",
       "      <td>74.287737</td>\n",
       "      <td>73.655303</td>\n",
       "      <td>65.273463</td>\n",
       "      <td>67.135263</td>\n",
       "      <td>61.810439</td>\n",
       "      <td>64.131609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>32.367500</td>\n",
       "      <td>-26.588900</td>\n",
       "      <td>398.400000</td>\n",
       "      <td>399.400000</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>129.400000</td>\n",
       "      <td>0.045302</td>\n",
       "      <td>0.039334</td>\n",
       "      <td>-0.892216</td>\n",
       "      <td>...</td>\n",
       "      <td>77.300000</td>\n",
       "      <td>73.600000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>72.400000</td>\n",
       "      <td>79.600000</td>\n",
       "      <td>74.100000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>72.900000</td>\n",
       "      <td>76.300000</td>\n",
       "      <td>76.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7920.7500</td>\n",
       "      <td>2998.700000</td>\n",
       "      <td>237.676000</td>\n",
       "      <td>551.400000</td>\n",
       "      <td>552.125000</td>\n",
       "      <td>490.500000</td>\n",
       "      <td>243.900000</td>\n",
       "      <td>1.580610</td>\n",
       "      <td>1.676430</td>\n",
       "      <td>1.660950</td>\n",
       "      <td>...</td>\n",
       "      <td>348.600000</td>\n",
       "      <td>458.500000</td>\n",
       "      <td>325.100000</td>\n",
       "      <td>307.700000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>311.800000</td>\n",
       "      <td>293.800000</td>\n",
       "      <td>286.600000</td>\n",
       "      <td>269.800000</td>\n",
       "      <td>280.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15840.5000</td>\n",
       "      <td>3000.650000</td>\n",
       "      <td>397.768000</td>\n",
       "      <td>595.700000</td>\n",
       "      <td>595.300000</td>\n",
       "      <td>532.300000</td>\n",
       "      <td>270.400000</td>\n",
       "      <td>2.352295</td>\n",
       "      <td>2.504070</td>\n",
       "      <td>2.387590</td>\n",
       "      <td>...</td>\n",
       "      <td>359.300000</td>\n",
       "      <td>512.700000</td>\n",
       "      <td>335.400000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>330.600000</td>\n",
       "      <td>320.800000</td>\n",
       "      <td>301.300000</td>\n",
       "      <td>295.200000</td>\n",
       "      <td>280.950000</td>\n",
       "      <td>289.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23760.2500</td>\n",
       "      <td>3002.170000</td>\n",
       "      <td>729.774000</td>\n",
       "      <td>609.800000</td>\n",
       "      <td>610.425000</td>\n",
       "      <td>543.800000</td>\n",
       "      <td>282.700000</td>\n",
       "      <td>4.178130</td>\n",
       "      <td>4.455908</td>\n",
       "      <td>4.282480</td>\n",
       "      <td>...</td>\n",
       "      <td>364.500000</td>\n",
       "      <td>526.500000</td>\n",
       "      <td>341.000000</td>\n",
       "      <td>321.100000</td>\n",
       "      <td>336.300000</td>\n",
       "      <td>326.400000</td>\n",
       "      <td>306.100000</td>\n",
       "      <td>299.600000</td>\n",
       "      <td>287.300000</td>\n",
       "      <td>295.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31680.0000</td>\n",
       "      <td>3261.280000</td>\n",
       "      <td>1051.680000</td>\n",
       "      <td>625.500000</td>\n",
       "      <td>625.300000</td>\n",
       "      <td>553.800000</td>\n",
       "      <td>292.800000</td>\n",
       "      <td>5.997180</td>\n",
       "      <td>6.400280</td>\n",
       "      <td>6.181350</td>\n",
       "      <td>...</td>\n",
       "      <td>447.700000</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>421.800000</td>\n",
       "      <td>429.500000</td>\n",
       "      <td>422.800000</td>\n",
       "      <td>430.900000</td>\n",
       "      <td>390.900000</td>\n",
       "      <td>396.600000</td>\n",
       "      <td>394.700000</td>\n",
       "      <td>399.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0             W             P           T0L           T0R  \\\n",
       "count  31680.0000  31680.000000  31680.000000  31680.000000  31680.000000   \n",
       "mean   15840.5000   2656.233474    432.091688    561.128188    563.492266   \n",
       "std     9145.3726    927.085374    305.557372     67.758272     65.252626   \n",
       "min        1.0000     32.367500    -26.588900    398.400000    399.400000   \n",
       "25%     7920.7500   2998.700000    237.676000    551.400000    552.125000   \n",
       "50%    15840.5000   3000.650000    397.768000    595.700000    595.300000   \n",
       "75%    23760.2500   3002.170000    729.774000    609.800000    610.425000   \n",
       "max    31680.0000   3261.280000   1051.680000    625.500000    625.300000   \n",
       "\n",
       "                 Tx            T1           Y0L           Y0R            Y1  \\\n",
       "count  31680.000000  31680.000000  31680.000000  31680.000000  31680.000000   \n",
       "mean     471.670777    248.994842      2.756224      2.935786      2.608339   \n",
       "std      133.874513     48.088155      1.421472      1.520984      1.762993   \n",
       "min       77.800000    129.400000      0.045302      0.039334     -0.892216   \n",
       "25%      490.500000    243.900000      1.580610      1.676430      1.660950   \n",
       "50%      532.300000    270.400000      2.352295      2.504070      2.387590   \n",
       "75%      543.800000    282.700000      4.178130      4.455908      4.282480   \n",
       "max      553.800000    292.800000      5.997180      6.400280      6.181350   \n",
       "\n",
       "       ...         TD3.1         TD4.1           TD1           TD2  \\\n",
       "count  ...  31680.000000  31680.000000  31680.000000  31680.000000   \n",
       "mean   ...    328.961897    453.129261    310.201357    293.069823   \n",
       "std    ...     84.311797    130.885639     75.916886     72.575196   \n",
       "min    ...     77.300000     73.600000     78.000000     72.400000   \n",
       "25%    ...    348.600000    458.500000    325.100000    307.700000   \n",
       "50%    ...    359.300000    512.700000    335.400000    316.000000   \n",
       "75%    ...    364.500000    526.500000    341.000000    321.100000   \n",
       "max    ...    447.700000    538.000000    421.800000    429.500000   \n",
       "\n",
       "                TD3           TD4           TD5           TD6           TD7  \\\n",
       "count  31680.000000  31680.000000  31680.000000  31680.000000  31680.000000   \n",
       "mean     306.183258    297.543472    278.528936    271.314905    259.272544   \n",
       "std       74.287737     73.655303     65.273463     67.135263     61.810439   \n",
       "min       79.600000     74.100000     83.000000     72.900000     76.300000   \n",
       "25%      321.000000    311.800000    293.800000    286.600000    269.800000   \n",
       "50%      330.600000    320.800000    301.300000    295.200000    280.950000   \n",
       "75%      336.300000    326.400000    306.100000    299.600000    287.300000   \n",
       "max      422.800000    430.900000    390.900000    396.600000    394.700000   \n",
       "\n",
       "                TD8  \n",
       "count  31680.000000  \n",
       "mean     267.263554  \n",
       "std       64.131609  \n",
       "min       76.700000  \n",
       "25%      280.600000  \n",
       "50%      289.400000  \n",
       "75%      295.000000  \n",
       "max      399.400000  \n",
       "\n",
       "[8 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_1.columns.values.tolist() \n",
    "all_data_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>W</th>\n",
       "      <th>P</th>\n",
       "      <th>T0L</th>\n",
       "      <th>T0R</th>\n",
       "      <th>Tx</th>\n",
       "      <th>T1</th>\n",
       "      <th>Y0L</th>\n",
       "      <th>Y0R</th>\n",
       "      <th>Y1</th>\n",
       "      <th>...</th>\n",
       "      <th>TD3.1</th>\n",
       "      <th>TD4.1</th>\n",
       "      <th>TD1</th>\n",
       "      <th>TD2</th>\n",
       "      <th>TD3</th>\n",
       "      <th>TD4</th>\n",
       "      <th>TD5</th>\n",
       "      <th>TD6</th>\n",
       "      <th>TD7</th>\n",
       "      <th>TD8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "      <td>23040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11520.500000</td>\n",
       "      <td>2485.867125</td>\n",
       "      <td>427.674703</td>\n",
       "      <td>571.714583</td>\n",
       "      <td>574.312157</td>\n",
       "      <td>493.860395</td>\n",
       "      <td>265.583754</td>\n",
       "      <td>2.495139</td>\n",
       "      <td>2.660487</td>\n",
       "      <td>2.595779</td>\n",
       "      <td>...</td>\n",
       "      <td>353.615391</td>\n",
       "      <td>475.348728</td>\n",
       "      <td>332.684588</td>\n",
       "      <td>314.917062</td>\n",
       "      <td>328.960451</td>\n",
       "      <td>320.243863</td>\n",
       "      <td>298.617418</td>\n",
       "      <td>293.257526</td>\n",
       "      <td>281.574635</td>\n",
       "      <td>291.339640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6651.219437</td>\n",
       "      <td>1108.606659</td>\n",
       "      <td>231.350071</td>\n",
       "      <td>69.485248</td>\n",
       "      <td>64.203408</td>\n",
       "      <td>99.667291</td>\n",
       "      <td>35.865969</td>\n",
       "      <td>1.199241</td>\n",
       "      <td>1.282542</td>\n",
       "      <td>1.140709</td>\n",
       "      <td>...</td>\n",
       "      <td>58.097327</td>\n",
       "      <td>94.032719</td>\n",
       "      <td>51.787462</td>\n",
       "      <td>49.478252</td>\n",
       "      <td>51.011208</td>\n",
       "      <td>50.413362</td>\n",
       "      <td>47.946620</td>\n",
       "      <td>48.636346</td>\n",
       "      <td>46.734690</td>\n",
       "      <td>47.751737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.144600</td>\n",
       "      <td>-6.089060</td>\n",
       "      <td>105.300000</td>\n",
       "      <td>104.500000</td>\n",
       "      <td>66.600000</td>\n",
       "      <td>81.600000</td>\n",
       "      <td>0.039334</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>-0.052011</td>\n",
       "      <td>...</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>68.100000</td>\n",
       "      <td>65.900000</td>\n",
       "      <td>69.100000</td>\n",
       "      <td>66.600000</td>\n",
       "      <td>69.800000</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>66.300000</td>\n",
       "      <td>67.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5760.750000</td>\n",
       "      <td>2997.700000</td>\n",
       "      <td>400.254000</td>\n",
       "      <td>589.400000</td>\n",
       "      <td>588.900000</td>\n",
       "      <td>527.200000</td>\n",
       "      <td>270.200000</td>\n",
       "      <td>2.307940</td>\n",
       "      <td>2.461210</td>\n",
       "      <td>2.361910</td>\n",
       "      <td>...</td>\n",
       "      <td>360.400000</td>\n",
       "      <td>508.500000</td>\n",
       "      <td>335.200000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>331.200000</td>\n",
       "      <td>323.500000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>296.700000</td>\n",
       "      <td>283.100000</td>\n",
       "      <td>293.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11520.500000</td>\n",
       "      <td>2998.490000</td>\n",
       "      <td>473.019000</td>\n",
       "      <td>599.500000</td>\n",
       "      <td>599.400000</td>\n",
       "      <td>535.800000</td>\n",
       "      <td>275.500000</td>\n",
       "      <td>2.686090</td>\n",
       "      <td>2.865130</td>\n",
       "      <td>2.751090</td>\n",
       "      <td>...</td>\n",
       "      <td>371.600000</td>\n",
       "      <td>513.200000</td>\n",
       "      <td>347.700000</td>\n",
       "      <td>325.600000</td>\n",
       "      <td>342.900000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>308.200000</td>\n",
       "      <td>300.900000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>297.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17280.250000</td>\n",
       "      <td>3000.990000</td>\n",
       "      <td>550.654000</td>\n",
       "      <td>603.800000</td>\n",
       "      <td>603.900000</td>\n",
       "      <td>538.900000</td>\n",
       "      <td>277.700000</td>\n",
       "      <td>3.118220</td>\n",
       "      <td>3.326820</td>\n",
       "      <td>3.191080</td>\n",
       "      <td>...</td>\n",
       "      <td>371.600000</td>\n",
       "      <td>513.200000</td>\n",
       "      <td>347.700000</td>\n",
       "      <td>325.600000</td>\n",
       "      <td>342.900000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>308.200000</td>\n",
       "      <td>300.900000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>297.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23040.000000</td>\n",
       "      <td>3009.500000</td>\n",
       "      <td>1009.670000</td>\n",
       "      <td>619.600000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>546.900000</td>\n",
       "      <td>284.400000</td>\n",
       "      <td>5.467390</td>\n",
       "      <td>5.853950</td>\n",
       "      <td>5.682220</td>\n",
       "      <td>...</td>\n",
       "      <td>410.100000</td>\n",
       "      <td>534.000000</td>\n",
       "      <td>386.900000</td>\n",
       "      <td>390.700000</td>\n",
       "      <td>387.200000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>359.800000</td>\n",
       "      <td>365.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             W             P           T0L           T0R  \\\n",
       "count  23040.000000  23040.000000  23040.000000  23040.000000  23040.000000   \n",
       "mean   11520.500000   2485.867125    427.674703    571.714583    574.312157   \n",
       "std     6651.219437   1108.606659    231.350071     69.485248     64.203408   \n",
       "min        1.000000     51.144600     -6.089060    105.300000    104.500000   \n",
       "25%     5760.750000   2997.700000    400.254000    589.400000    588.900000   \n",
       "50%    11520.500000   2998.490000    473.019000    599.500000    599.400000   \n",
       "75%    17280.250000   3000.990000    550.654000    603.800000    603.900000   \n",
       "max    23040.000000   3009.500000   1009.670000    619.600000    619.000000   \n",
       "\n",
       "                 Tx            T1           Y0L           Y0R            Y1  \\\n",
       "count  23040.000000  23040.000000  23040.000000  23040.000000  23040.000000   \n",
       "mean     493.860395    265.583754      2.495139      2.660487      2.595779   \n",
       "std       99.667291     35.865969      1.199241      1.282542      1.140709   \n",
       "min       66.600000     81.600000      0.039334      0.033095     -0.052011   \n",
       "25%      527.200000    270.200000      2.307940      2.461210      2.361910   \n",
       "50%      535.800000    275.500000      2.686090      2.865130      2.751090   \n",
       "75%      538.900000    277.700000      3.118220      3.326820      3.191080   \n",
       "max      546.900000    284.400000      5.467390      5.853950      5.682220   \n",
       "\n",
       "       ...         TD3.1         TD4.1           TD1           TD2  \\\n",
       "count  ...  23040.000000  23040.000000  23040.000000  23040.000000   \n",
       "mean   ...    353.615391    475.348728    332.684588    314.917062   \n",
       "std    ...     58.097327     94.032719     51.787462     49.478252   \n",
       "min    ...     68.300000     67.100000     68.100000     65.900000   \n",
       "25%    ...    360.400000    508.500000    335.200000    318.500000   \n",
       "50%    ...    371.600000    513.200000    347.700000    325.600000   \n",
       "75%    ...    371.600000    513.200000    347.700000    325.600000   \n",
       "max    ...    410.100000    534.000000    386.900000    390.700000   \n",
       "\n",
       "                TD3           TD4           TD5           TD6           TD7  \\\n",
       "count  23040.000000  23040.000000  23040.000000  23040.000000  23040.000000   \n",
       "mean     328.960451    320.243863    298.617418    293.257526    281.574635   \n",
       "std       51.011208     50.413362     47.946620     48.636346     46.734690   \n",
       "min       69.100000     66.600000     69.800000     64.900000     66.300000   \n",
       "25%      331.200000    323.500000    303.000000    296.700000    283.100000   \n",
       "50%      342.900000    332.000000    308.200000    300.900000    286.000000   \n",
       "75%      342.900000    332.000000    308.200000    300.900000    286.000000   \n",
       "max      387.200000    394.000000    361.000000    362.000000    359.800000   \n",
       "\n",
       "                TD8  \n",
       "count  23040.000000  \n",
       "mean     291.339640  \n",
       "std       47.751737  \n",
       "min       67.700000  \n",
       "25%      293.000000  \n",
       "50%      297.100000  \n",
       "75%      297.100000  \n",
       "max      365.900000  \n",
       "\n",
       "[8 rows x 52 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_2.columns.values.tolist() \n",
    "all_data_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([all_data_1,all_data_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>W</th>\n",
       "      <th>P</th>\n",
       "      <th>T0L</th>\n",
       "      <th>T0R</th>\n",
       "      <th>Tx</th>\n",
       "      <th>T1</th>\n",
       "      <th>Y0L</th>\n",
       "      <th>Y0R</th>\n",
       "      <th>Y1</th>\n",
       "      <th>...</th>\n",
       "      <th>TD3.1</th>\n",
       "      <th>TD4.1</th>\n",
       "      <th>TD1</th>\n",
       "      <th>TD2</th>\n",
       "      <th>TD3</th>\n",
       "      <th>TD4</th>\n",
       "      <th>TD5</th>\n",
       "      <th>TD6</th>\n",
       "      <th>TD7</th>\n",
       "      <th>TD8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.00000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "      <td>54720.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14021.552632</td>\n",
       "      <td>2584.500274</td>\n",
       "      <td>430.231905</td>\n",
       "      <td>565.585618</td>\n",
       "      <td>568.04801</td>\n",
       "      <td>481.013774</td>\n",
       "      <td>255.979647</td>\n",
       "      <td>2.646293</td>\n",
       "      <td>2.819871</td>\n",
       "      <td>2.603050</td>\n",
       "      <td>...</td>\n",
       "      <td>339.342315</td>\n",
       "      <td>462.484826</td>\n",
       "      <td>319.667981</td>\n",
       "      <td>302.268660</td>\n",
       "      <td>315.773655</td>\n",
       "      <td>307.101531</td>\n",
       "      <td>286.987244</td>\n",
       "      <td>280.553904</td>\n",
       "      <td>268.662898</td>\n",
       "      <td>277.400853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8461.500543</td>\n",
       "      <td>1011.004968</td>\n",
       "      <td>276.754420</td>\n",
       "      <td>68.689251</td>\n",
       "      <td>65.03212</td>\n",
       "      <td>121.154687</td>\n",
       "      <td>44.130261</td>\n",
       "      <td>1.338636</td>\n",
       "      <td>1.431911</td>\n",
       "      <td>1.532101</td>\n",
       "      <td>...</td>\n",
       "      <td>75.396862</td>\n",
       "      <td>117.307775</td>\n",
       "      <td>67.742757</td>\n",
       "      <td>64.780183</td>\n",
       "      <td>66.460939</td>\n",
       "      <td>65.852157</td>\n",
       "      <td>59.438562</td>\n",
       "      <td>61.013995</td>\n",
       "      <td>57.032585</td>\n",
       "      <td>59.012507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.367500</td>\n",
       "      <td>-26.588900</td>\n",
       "      <td>105.300000</td>\n",
       "      <td>104.50000</td>\n",
       "      <td>66.600000</td>\n",
       "      <td>81.600000</td>\n",
       "      <td>0.039334</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>-0.892216</td>\n",
       "      <td>...</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>68.100000</td>\n",
       "      <td>65.900000</td>\n",
       "      <td>69.100000</td>\n",
       "      <td>66.600000</td>\n",
       "      <td>69.800000</td>\n",
       "      <td>64.900000</td>\n",
       "      <td>66.300000</td>\n",
       "      <td>67.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6840.750000</td>\n",
       "      <td>2998.010000</td>\n",
       "      <td>250.058000</td>\n",
       "      <td>558.600000</td>\n",
       "      <td>563.00000</td>\n",
       "      <td>499.900000</td>\n",
       "      <td>257.800000</td>\n",
       "      <td>1.617570</td>\n",
       "      <td>1.716580</td>\n",
       "      <td>1.698570</td>\n",
       "      <td>...</td>\n",
       "      <td>352.900000</td>\n",
       "      <td>477.700000</td>\n",
       "      <td>328.800000</td>\n",
       "      <td>311.200000</td>\n",
       "      <td>324.500000</td>\n",
       "      <td>315.800000</td>\n",
       "      <td>297.100000</td>\n",
       "      <td>290.600000</td>\n",
       "      <td>277.300000</td>\n",
       "      <td>285.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13680.500000</td>\n",
       "      <td>2999.910000</td>\n",
       "      <td>445.821000</td>\n",
       "      <td>598.300000</td>\n",
       "      <td>597.70000</td>\n",
       "      <td>534.300000</td>\n",
       "      <td>274.100000</td>\n",
       "      <td>2.592500</td>\n",
       "      <td>2.764625</td>\n",
       "      <td>2.623050</td>\n",
       "      <td>...</td>\n",
       "      <td>361.700000</td>\n",
       "      <td>513.200000</td>\n",
       "      <td>338.200000</td>\n",
       "      <td>318.800000</td>\n",
       "      <td>333.500000</td>\n",
       "      <td>323.900000</td>\n",
       "      <td>304.200000</td>\n",
       "      <td>297.800000</td>\n",
       "      <td>284.900000</td>\n",
       "      <td>293.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20520.250000</td>\n",
       "      <td>3001.920000</td>\n",
       "      <td>604.669250</td>\n",
       "      <td>605.400000</td>\n",
       "      <td>605.80000</td>\n",
       "      <td>540.100000</td>\n",
       "      <td>278.900000</td>\n",
       "      <td>3.431597</td>\n",
       "      <td>3.658515</td>\n",
       "      <td>3.542643</td>\n",
       "      <td>...</td>\n",
       "      <td>371.600000</td>\n",
       "      <td>521.000000</td>\n",
       "      <td>347.700000</td>\n",
       "      <td>325.600000</td>\n",
       "      <td>342.900000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>308.200000</td>\n",
       "      <td>300.900000</td>\n",
       "      <td>286.600000</td>\n",
       "      <td>297.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31680.000000</td>\n",
       "      <td>3261.280000</td>\n",
       "      <td>1051.680000</td>\n",
       "      <td>625.500000</td>\n",
       "      <td>625.30000</td>\n",
       "      <td>553.800000</td>\n",
       "      <td>292.800000</td>\n",
       "      <td>5.997180</td>\n",
       "      <td>6.400280</td>\n",
       "      <td>6.181350</td>\n",
       "      <td>...</td>\n",
       "      <td>447.700000</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>421.800000</td>\n",
       "      <td>429.500000</td>\n",
       "      <td>422.800000</td>\n",
       "      <td>430.900000</td>\n",
       "      <td>390.900000</td>\n",
       "      <td>396.600000</td>\n",
       "      <td>394.700000</td>\n",
       "      <td>399.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             W             P           T0L          T0R  \\\n",
       "count  54720.000000  54720.000000  54720.000000  54720.000000  54720.00000   \n",
       "mean   14021.552632   2584.500274    430.231905    565.585618    568.04801   \n",
       "std     8461.500543   1011.004968    276.754420     68.689251     65.03212   \n",
       "min        1.000000     32.367500    -26.588900    105.300000    104.50000   \n",
       "25%     6840.750000   2998.010000    250.058000    558.600000    563.00000   \n",
       "50%    13680.500000   2999.910000    445.821000    598.300000    597.70000   \n",
       "75%    20520.250000   3001.920000    604.669250    605.400000    605.80000   \n",
       "max    31680.000000   3261.280000   1051.680000    625.500000    625.30000   \n",
       "\n",
       "                 Tx            T1           Y0L           Y0R            Y1  \\\n",
       "count  54720.000000  54720.000000  54720.000000  54720.000000  54720.000000   \n",
       "mean     481.013774    255.979647      2.646293      2.819871      2.603050   \n",
       "std      121.154687     44.130261      1.338636      1.431911      1.532101   \n",
       "min       66.600000     81.600000      0.039334      0.033095     -0.892216   \n",
       "25%      499.900000    257.800000      1.617570      1.716580      1.698570   \n",
       "50%      534.300000    274.100000      2.592500      2.764625      2.623050   \n",
       "75%      540.100000    278.900000      3.431597      3.658515      3.542643   \n",
       "max      553.800000    292.800000      5.997180      6.400280      6.181350   \n",
       "\n",
       "       ...         TD3.1         TD4.1           TD1           TD2  \\\n",
       "count  ...  54720.000000  54720.000000  54720.000000  54720.000000   \n",
       "mean   ...    339.342315    462.484826    319.667981    302.268660   \n",
       "std    ...     75.396862    117.307775     67.742757     64.780183   \n",
       "min    ...     68.300000     67.100000     68.100000     65.900000   \n",
       "25%    ...    352.900000    477.700000    328.800000    311.200000   \n",
       "50%    ...    361.700000    513.200000    338.200000    318.800000   \n",
       "75%    ...    371.600000    521.000000    347.700000    325.600000   \n",
       "max    ...    447.700000    538.000000    421.800000    429.500000   \n",
       "\n",
       "                TD3           TD4           TD5           TD6           TD7  \\\n",
       "count  54720.000000  54720.000000  54720.000000  54720.000000  54720.000000   \n",
       "mean     315.773655    307.101531    286.987244    280.553904    268.662898   \n",
       "std       66.460939     65.852157     59.438562     61.013995     57.032585   \n",
       "min       69.100000     66.600000     69.800000     64.900000     66.300000   \n",
       "25%      324.500000    315.800000    297.100000    290.600000    277.300000   \n",
       "50%      333.500000    323.900000    304.200000    297.800000    284.900000   \n",
       "75%      342.900000    332.000000    308.200000    300.900000    286.600000   \n",
       "max      422.800000    430.900000    390.900000    396.600000    394.700000   \n",
       "\n",
       "                TD8  \n",
       "count  54720.000000  \n",
       "mean     277.400853  \n",
       "std       59.012507  \n",
       "min       67.700000  \n",
       "25%      285.800000  \n",
       "50%      293.300000  \n",
       "75%      297.100000  \n",
       "max      399.400000  \n",
       "\n",
       "[8 rows x 52 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.columns.values.tolist() \n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44.2 60.2]\n",
      "[671.36 424.16]\n",
      "original data: \n",
      "[[32 42]\n",
      " [86 61]\n",
      " [31 38]\n",
      " [12 96]\n",
      " [60 64]]\n",
      "transformed data: \n",
      "[[-0.47084948 -0.88370341]\n",
      " [ 1.6132384   0.03884411]\n",
      " [-0.5094437  -1.07792394]\n",
      " [-1.24273389  1.73827375]\n",
      " [ 0.60978868  0.1845095 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = np.random.randint(100,size=(5,2))\n",
    "data = np.array([[32 ,42],\n",
    " [86 ,61],\n",
    " [31 ,38],\n",
    " [12 ,96],\n",
    " [60 ,64]])\n",
    "scaler = StandardScaler()\n",
    "train_mean = scaler.fit(data).mean_\n",
    "train_std = scaler.fit(data).var_\n",
    "print(train_mean)\n",
    "print(train_std)\n",
    "trans_data = scaler.transform(data)\n",
    "print('original data: ')\n",
    "print(data)\n",
    "print('transformed data: ')\n",
    "print(trans_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31680, 6)\n",
      "(31680, 2, 3, 1)\n",
      "(31680, 38)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# all_data_array = all_data.values\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(all_data_array[:,1:7])\n",
    "# all_data_Normalized  = scaler.transform(all_data_array[:,1:7])\n",
    "# x_data_1 = all_data_Normalized[:,0:3]\n",
    "# x_data_2 = all_data_Normalized[:,3:]\n",
    "# print(all_data_Normalized.shape)\n",
    "# x_data = []\n",
    "# for a,b in zip(x_data_1,x_data_2):\n",
    "#     x_data_single = [a,b]\n",
    "#     x_data.append(x_data_single)\n",
    "# # x_data = np.concatenate((x_data_1,x_data_2),axis=)\n",
    "# x_data = np.array(x_data)\n",
    "# # print(x_data.shape)\n",
    "# x_data = np.expand_dims(x_data,axis = 3)\n",
    "# print(x_data.shape)\n",
    "# # #11和12是空的\n",
    "# y_data_1 = all_data_array[:,7:11]\n",
    "# y_data_2 = all_data_array[:,13:]\n",
    "# y_data = np.concatenate((y_data_1,y_data_2),axis=1)\n",
    "# print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54720, 11)\n",
      "(54720, 4, 3, 1)\n",
      "(54720, 37)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "all_data_array = all_data.values\n",
    "scalerX_pre = StandardScaler()\n",
    "scalerX = scalerX_pre.fit(all_data_array[:,1:12])\n",
    "x_data_Normalized  = scalerX.transform(all_data_array[:,1:12])\n",
    "x_data_1 = x_data_Normalized[:,0:3]\n",
    "x_data_2 = x_data_Normalized[:,3:6]\n",
    "x_data_3 = x_data_Normalized[:,6:9]\n",
    "x_data_4 = x_data_Normalized[:,9:]\n",
    "x_data_4_zero = np.zeros((x_data_4.shape[0],1))\n",
    "x_data_4 = np.concatenate((x_data_4,x_data_4_zero),axis=1)\n",
    "print(x_data_Normalized.shape)\n",
    "x_data = []\n",
    "for a,b,c,d in zip(x_data_1,x_data_2,x_data_3,x_data_4):\n",
    "    x_data_single = [a,b,c,d]\n",
    "    x_data.append(x_data_single)\n",
    "# x_data = np.concatenate((x_data_1,x_data_2),axis=)\n",
    "x_data = np.array(x_data)\n",
    "# print(x_data.shape)\n",
    "x_data = np.expand_dims(x_data,axis = 3)\n",
    "print(x_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "# #11和12是空的\n",
    "y_data_1 = all_data_array[:,12:15]\n",
    "y_data_2 = all_data_array[:,18:52]\n",
    "y_data = np.concatenate((y_data_1,y_data_2),axis=1)\n",
    "scalery_pre = StandardScaler()\n",
    "scalery = scalery_pre.fit(y_data[:,:])\n",
    "y_data = scalery.transform(y_data[:,:])\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    " \n",
    "if gpus:\n",
    "    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n",
    "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
    "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
    "    tf.config.set_visible_devices([gpu0],\"GPU\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51984, 4, 3, 1)\n",
      "(51984, 37)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "seed = 2022\n",
    "X_pre_train, X_test, y_pre_train, y_test = train_test_split(x_data, y_data, \n",
    "                                                           random_state=seed, train_size=0.95, \n",
    "                                                           test_size=0.05)\n",
    "print(X_pre_train.shape)\n",
    "print(y_pre_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "learning_rate = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.1, \n",
    "    patience=20, \n",
    "    verbose=0, \n",
    "    mode='auto', \n",
    "    min_delta=0.00000001, \n",
    "    cooldown=0, \n",
    "    min_lr=0\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=100, \n",
    "    verbose=2\n",
    ")\n",
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 4, 3, 32)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 4, 3, 32)          4128      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 4, 3, 64)          8256      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 3, 64)          65600     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 4, 3, 128)         32896     \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 3, 128)         262272    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               768500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 37)                3737      \n",
      "=================================================================\n",
      "Total params: 1,195,649\n",
      "Trainable params: 1,195,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras.applications.resnet18 import ResNet18\n",
    "# from keras.applications.resnet18 import preprocess_input as preprocess_input_resnet\n",
    "import tensorflow as tf\n",
    "import os\n",
    "# import tensorflow.keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "def deeper_conv2D_test1(h,w):\n",
    "    new_model = tf.keras.Sequential()\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), strides=1, padding=\"same\", activation=\"relu\", \\\n",
    "                                         input_shape=(h, w, 1)))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding=\"same\", activation=\"relu\"))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding=\"same\", activation=\"relu\"))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=4, padding=\"same\", activation=\"relu\"))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, padding=\"same\", activation=\"relu\"))\n",
    "    new_model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=4, padding=\"same\", activation=\"relu\"))\n",
    "    # Flatten will take our convolution filters and lay them out end to end so our dense layer can predict based on the outcomes of each\n",
    "    new_model.add(tf.keras.layers.Flatten())\n",
    "    new_model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
    "    new_model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "    new_model.add(tf.keras.layers.Dense(37))\n",
    "    new_model.compile(optimizer=\"adam\", loss=\"mean_absolute_error\")    \n",
    "    return new_model\n",
    "m1 = deeper_conv2D_test1(x_data.shape[1],x_data.shape[2])\n",
    "# m2 = deeper_conv2D(pre_data_x.shape[1],pre_data_x.shape[2])\n",
    "m1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0839 - val_loss: 0.0352 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0372 - val_loss: 0.0315 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0343 - val_loss: 0.0279 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0297 - val_loss: 0.0311 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0277 - val_loss: 0.0341 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0268 - val_loss: 0.0269 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0265 - val_loss: 0.0413 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0241 - val_loss: 0.0279 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0236 - val_loss: 0.0305 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0216 - val_loss: 0.0193 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0217 - val_loss: 0.0256 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0216 - val_loss: 0.0195 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0208 - val_loss: 0.0240 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0193 - val_loss: 0.0171 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0185 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0240 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0180 - val_loss: 0.0179 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0193 - val_loss: 0.0288 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0178 - val_loss: 0.0156 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0140 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0192 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0161 - val_loss: 0.0237 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0156 - val_loss: 0.0193 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0157 - val_loss: 0.0161 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0147 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0164 - val_loss: 0.0164 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0215 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0154 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0146 - val_loss: 0.0166 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0137 - val_loss: 0.0226 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0144 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0136 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0141 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0172 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0134 - val_loss: 0.0175 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0132 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0128 - val_loss: 0.0121 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0124 - val_loss: 0.0130 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0126 - val_loss: 0.0157 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0139 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0143 - val_loss: 0.0148 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0125 - val_loss: 0.0160 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0123 - val_loss: 0.0158 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0122 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0113 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0119 - val_loss: 0.0148 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0114 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0129 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0118 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0108 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0147 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0111 - val_loss: 0.0107 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0105 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0122 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0104 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0107 - val_loss: 0.0149 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0112 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0116 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0098 - val_loss: 0.0114 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0153 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0101 - val_loss: 0.0138 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0096 - val_loss: 0.0124 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0099 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0103 - val_loss: 0.0136 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0097 - val_loss: 0.0126 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0106 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0135 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0102 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0092 - val_loss: 0.0099 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0095 - val_loss: 0.0092 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0089 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0090 - val_loss: 0.0097 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0125 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0093 - val_loss: 0.0155 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0091 - val_loss: 0.0128 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0092 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0085 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0088 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0086 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0080 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0081 - val_loss: 0.0079 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0111 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0087 - val_loss: 0.0101 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0084 - val_loss: 0.0109 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0080 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0083 - val_loss: 0.0091 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0118 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0088 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0087 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0093 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0075 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0082 - val_loss: 0.0096 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0078 - val_loss: 0.0086 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0076 - val_loss: 0.0113 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0084 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0079 - val_loss: 0.0083 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0077 - val_loss: 0.0110 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0080 - val_loss: 0.0117 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0043 - val_loss: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0035 - val_loss: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0034 - val_loss: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0034 - val_loss: 0.0041 - lr: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0033 - val_loss: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0033 - val_loss: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0033 - val_loss: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0032 - val_loss: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0032 - val_loss: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0031 - val_loss: 0.0037 - lr: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0031 - val_loss: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0031 - val_loss: 0.0037 - lr: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0031 - val_loss: 0.0040 - lr: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0030 - val_loss: 0.0037 - lr: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0030 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0030 - val_loss: 0.0037 - lr: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0030 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0030 - val_loss: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0030 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0038 - lr: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0037 - lr: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0028 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0039 - lr: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0027 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0026 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 167/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 178/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0025 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0037 - lr: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0036 - lr: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0024 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0037 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0034 - lr: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0035 - lr: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0023 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 221/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0033 - lr: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0032 - lr: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0022 - val_loss: 0.0031 - lr: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0030 - lr: 1.0000e-05\n",
      "Epoch 232/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 233/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 234/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 235/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 236/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 237/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 238/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 239/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 240/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 241/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 242/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 243/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 244/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 245/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 246/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 247/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 248/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 249/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 250/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 251/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 252/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 253/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 254/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 255/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 256/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 257/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 258/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 259/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 260/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 261/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 262/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 263/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 264/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 265/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 266/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 267/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 268/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 269/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 270/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 271/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 272/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 273/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 274/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 275/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 276/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 277/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 278/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 279/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 280/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 281/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 282/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 283/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 284/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 285/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 286/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 287/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 288/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 289/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 290/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 291/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 292/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 293/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 294/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 295/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 296/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 297/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 298/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 299/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 300/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 301/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 302/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 303/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 304/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 305/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 306/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 307/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 308/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 309/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 310/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 311/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 312/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 313/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 314/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0019 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 315/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 316/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 317/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 318/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 319/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 320/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 321/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 322/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 323/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 324/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 325/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 326/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 327/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 328/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 329/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 330/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 331/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 332/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 333/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 334/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 335/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 336/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 337/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 338/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 339/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 340/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 341/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 342/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 343/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 344/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 346/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0029 - lr: 1.0000e-05\n",
      "Epoch 347/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 348/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 349/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 350/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 351/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 352/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 353/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 354/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 355/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 356/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 357/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 358/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 359/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 360/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 361/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 362/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 363/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 364/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 365/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 366/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 367/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 368/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 369/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 370/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 371/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 372/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 373/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 374/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 375/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 376/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 377/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 378/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 379/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 380/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 381/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 382/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 383/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 384/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 385/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 386/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 387/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 388/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 389/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 390/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 391/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 392/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 393/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 394/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 395/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 396/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 397/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-06\n",
      "Epoch 398/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 399/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 400/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 401/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 402/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 403/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 404/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 405/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 406/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 407/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 408/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 409/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 410/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 411/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 412/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 414/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 415/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 416/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 417/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 418/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 419/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 420/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 421/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 422/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 423/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 424/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 425/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 426/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 427/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 428/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 429/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 430/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 431/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 432/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 433/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 434/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 435/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 436/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 437/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 438/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 439/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 440/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 441/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 442/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 443/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 444/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 445/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 446/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 447/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 448/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 449/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 450/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 451/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 452/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 453/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 454/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 455/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 456/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 457/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 458/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 459/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 460/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 461/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 462/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 463/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 464/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 465/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 466/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 467/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 468/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 469/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 470/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 471/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 472/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 473/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 474/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 475/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 476/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 477/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 478/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-07\n",
      "Epoch 479/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 480/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 482/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 483/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 484/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 485/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 486/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 487/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 488/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 489/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 490/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 491/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 492/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 493/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 494/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 495/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 496/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 497/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 498/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-08\n",
      "Epoch 499/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 500/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 501/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 502/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 503/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 504/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 505/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 506/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 507/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 508/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 509/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 510/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 511/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 512/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 513/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 514/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 515/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 516/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 517/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 518/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-09\n",
      "Epoch 519/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 520/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 521/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 522/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 523/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 524/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 525/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 526/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 527/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 528/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 529/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 530/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 531/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 532/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 533/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 534/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 535/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 536/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 537/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 538/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-10\n",
      "Epoch 539/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 540/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 541/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 542/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 543/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 544/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 545/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 546/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 547/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 548/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 549/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 550/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 551/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 552/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 553/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 554/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 555/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 556/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 557/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 558/1000\n",
      "407/407 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0028 - lr: 1.0000e-11\n",
      "Epoch 00558: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = m1.fit(X_pre_train,  y_pre_train, epochs=1000, batch_size=128, callbacks=[learning_rate, early_stopping] ,\n",
    "                     validation_data = (X_test,  y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.save('./models/test_01_model_all_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
